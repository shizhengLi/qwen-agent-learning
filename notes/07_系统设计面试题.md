# Qwen-Agent 系统设计面试题

## 1. 基础系统设计

### 1.1 系统架构设计

**问题1：请设计一个支持大规模用户访问的AI Agent平台，包括系统架构、技术选型和关键组件。**

**参考答案：**
**系统架构设计：**

```
┌─────────────────────────────────────────────────────────────────┐
│                         负载均衡层                              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │   Nginx     │  │   HAProxy   │  │   CloudFlare│              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         API网关层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  认证授权    │  │  限流熔断    │  │  路由转发    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         业务服务层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │ Agent服务   │  │  LLM服务    │  │  工具服务   │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  记忆服务   │  │  用户服务   │  │  文件服务   │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         基础设施层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  消息队列    │  │  缓存系统    │  │  数据库      │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  对象存储    │  │  监控系统    │  │  日志系统    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
```

**技术选型：**

1. **负载均衡**：
   - Nginx：HTTP负载均衡
   - HAProxy：TCP负载均衡
   - CloudFlare：CDN和DDoS防护

2. **API网关**：
   - Kong/Kong：API管理和微服务网关
   - 功能：认证、限流、监控、路由

3. **业务服务**：
   - 框架：FastAPI（Python）/Spring Boot（Java）
   - 容器化：Docker + Kubernetes
   - 服务发现：Consul/Etcd

4. **基础设施**：
   - 消息队列：RabbitMQ/Kafka
   - 缓存：Redis Cluster
   - 数据库：PostgreSQL + MongoDB
   - 对象存储：MinIO/AWS S3

**关键组件设计：**

1. **Agent服务**：
```python
class AgentService:
    def __init__(self):
        self.llm_pool = LLMPool()
        self.tool_registry = ToolRegistry()
        self.memory_manager = MemoryManager()
        self.rate_limiter = RateLimiter()
    
    async def process_message(self, request: AgentRequest) -> AgentResponse:
        # 1. 限流检查
        await self.rate_limiter.check_limit(request.user_id)
        
        # 2. 获取Agent实例
        agent = await self.get_agent_instance(request.agent_id)
        
        # 3. 处理消息
        response = await agent.process_message(
            request.message,
            request.conversation_id
        )
        
        # 4. 记录日志
        await self.log_interaction(request, response)
        
        return response
```

2. **LLM服务**：
```python
class LLMService:
    def __init__(self):
        self.model_providers = {
            'openai': OpenAIProvider(),
            'qwen': QwenProvider(),
            'claude': ClaudeProvider()
        }
        self.cache = RedisCache()
        self.load_balancer = LoadBalancer()
    
    async def chat(self, request: ChatRequest) -> ChatResponse:
        # 1. 检查缓存
        cache_key = self.generate_cache_key(request)
        cached_response = await self.cache.get(cache_key)
        if cached_response:
            return cached_response
        
        # 2. 负载均衡选择模型
        provider = self.load_balancer.select_provider(
            request.model_type
        )
        
        # 3. 调用模型
        response = await provider.chat(request)
        
        # 4. 缓存结果
        await self.cache.set(cache_key, response, ttl=3600)
        
        return response
```

3. **工具服务**：
```python
class ToolService:
    def __init__(self):
        self.tool_registry = ToolRegistry()
        self.sandbox = Sandbox()
        self.monitor = ToolMonitor()
    
    async def execute_tool(self, request: ToolRequest) -> ToolResponse:
        # 1. 验证工具
        tool = self.tool_registry.get_tool(request.tool_name)
        if not tool:
            raise ToolNotFoundError(request.tool_name)
        
        # 2. 安全检查
        await self.sandbox.validate_request(request)
        
        # 3. 执行工具
        start_time = time.time()
        try:
            result = await tool.execute(request.parameters)
            execution_time = time.time() - start_time
            
            # 4. 记录监控
            await self.monitor.record_execution(
                request.tool_name,
                execution_time,
                success=True
            )
            
            return ToolResponse(
                success=True,
                result=result,
                execution_time=execution_time
            )
            
        except Exception as e:
            await self.monitor.record_execution(
                request.tool_name,
                time.time() - start_time,
                success=False
            )
            raise ToolExecutionError(str(e))
```

**性能优化策略：**

1. **水平扩展**：
   - 微服务架构支持独立扩展
   - 自动扩缩容基于CPU/内存使用率
   - 数据库读写分离和分库分表

2. **缓存优化**：
   - 多级缓存（内存+Redis）
   - 智能缓存失效策略
   - 缓存预热和降级

3. **连接池优化**：
   - HTTP连接池复用
   - 数据库连接池管理
   - 模型API连接优化

---

**问题2：设计一个支持实时对话的AI Agent系统，要求支持百万级并发连接，如何设计架构？**

**参考答案：**
**实时对话系统架构：**

```
┌─────────────────────────────────────────────────────────────────┐
│                         客户端层                                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Web应用    │  │  移动应用   │  │  桌面应用   │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         连接管理层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  WebSocket  │  │  HTTP/2     │  │  gRPC       │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Socket.io  │  │  Long Poll  │  │  SSE        │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         消息路由层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Redis Pub  │  │  Kafka      │  │  RabbitMQ   │              │
│  │  Sub        │  │  Streams    │  │  Topics     │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         业务处理层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  消息处理器  │  │  对话管理器  │  │  状态管理器  │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Agent实例  │  │  LLM调用器   │  │  工具执行器  │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         数据存储层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Redis      │  │  MongoDB    │  │  PostgreSQL │              │
│  │  (状态)     │  │  (对话)     │  │  (用户)     │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
```

**关键技术实现：**

1. **WebSocket连接管理**：
```python
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.user_connections: Dict[str, Set[str]] = {}
        self.connection_stats = ConnectionStats()
    
    async def connect(self, websocket: WebSocket, user_id: str):
        """建立WebSocket连接"""
        connection_id = str(uuid.uuid4())
        self.active_connections[connection_id] = websocket
        self.connection_stats.add_connection()
        
        # 记录用户连接
        if user_id not in self.user_connections:
            self.user_connections[user_id] = set()
        self.user_connections[user_id].add(connection_id)
        
        return connection_id
    
    async def disconnect(self, connection_id: str, user_id: str):
        """断开WebSocket连接"""
        if connection_id in self.active_connections:
            del self.active_connections[connection_id]
            self.connection_stats.remove_connection()
        
        # 清理用户连接记录
        if user_id in self.user_connections:
            self.user_connections[user_id].discard(connection_id)
            if not self.user_connections[user_id]:
                del self.user_connections[user_id]
    
    async def send_message(self, user_id: str, message: str):
        """向用户发送消息"""
        if user_id not in self.user_connections:
            return
        
        # 广播到用户的所有连接
        for connection_id in self.user_connections[user_id]:
            if connection_id in self.active_connections:
                websocket = self.active_connections[connection_id]
                try:
                    await websocket.send_text(message)
                except:
                    # 连接已断开，清理
                    await self.disconnect(connection_id, user_id)
    
    def get_user_connections(self, user_id: str) -> int:
        """获取用户连接数"""
        return len(self.user_connections.get(user_id, set()))
```

2. **消息路由系统**：
```python
class MessageRouter:
    def __init__(self):
        self.redis_client = redis.Redis()
        self.processors: Dict[str, MessageProcessor] = {}
        self.load_balancer = LoadBalancer()
    
    async def route_message(self, message: IncomingMessage):
        """路由消息到对应的处理器"""
        # 1. 选择处理器
        processor_key = self.select_processor(message)
        processor = self.processors.get(processor_key)
        
        if not processor:
            # 动态创建处理器
            processor = await self.create_processor(processor_key)
            self.processors[processor_key] = processor
        
        # 2. 异步处理消息
        asyncio.create_task(processor.process_message(message))
    
    async def create_processor(self, processor_key: str) -> MessageProcessor:
        """创建消息处理器"""
        processor = MessageProcessor(processor_key)
        
        # 启动处理器
        await processor.start()
        
        # 注册健康检查
        await self.register_health_check(processor)
        
        return processor
    
    def select_processor(self, message: IncomingMessage) -> str:
        """选择处理器"""
        # 基于用户ID的哈希分配
        user_hash = hash(message.user_id)
        processor_count = len(self.processors) or 1
        processor_index = user_hash % processor_count
        
        return f"processor_{processor_index}"

class MessageProcessor:
    def __init__(self, processor_id: str):
        self.processor_id = processor_id
        self.agent_pool = AgentPool()
        self.message_queue = asyncio.Queue()
        self.running = False
    
    async def start(self):
        """启动处理器"""
        self.running = True
        asyncio.create_task(self.process_messages())
    
    async def process_messages(self):
        """处理消息队列"""
        while self.running:
            try:
                message = await self.message_queue.get()
                await self.handle_message(message)
            except Exception as e:
                print(f"Error processing message: {e}")
    
    async def handle_message(self, message: IncomingMessage):
        """处理单个消息"""
        # 1. 获取Agent实例
        agent = await self.agent_pool.get_agent(message.agent_id)
        
        # 2. 处理消息
        response = await agent.process_message(
            message.content,
            message.conversation_id
        )
        
        # 3. 发送响应
        await self.send_response(message.user_id, response)
```

3. **Agent池管理**：
```python
class AgentPool:
    def __init__(self, pool_size: int = 10):
        self.pool_size = pool_size
        self.agents: Dict[str, Agent] = {}
        self.agent_locks: Dict[str, asyncio.Lock] = {}
        self.stats = PoolStats()
    
    async def get_agent(self, agent_id: str) -> Agent:
        """获取Agent实例"""
        if agent_id not in self.agents:
            async with self._get_agent_lock(agent_id):
                # 双重检查
                if agent_id not in self.agents:
                    self.agents[agent_id] = await self.create_agent(agent_id)
        
        return self.agents[agent_id]
    
    async def create_agent(self, agent_id: str) -> Agent:
        """创建Agent实例"""
        # 从配置加载Agent配置
        config = await self.load_agent_config(agent_id)
        
        # 创建Agent
        agent = Agent(
            agent_id=agent_id,
            config=config,
            message_handler=self.message_handler
        )
        
        # 初始化Agent
        await agent.initialize()
        
        self.stats.add_agent()
        return agent
    
    async def message_handler(self, response: AgentResponse):
        """处理Agent响应"""
        # 通过消息总线发送响应
        await self.message_bus.publish(
            topic=f"agent_response_{response.user_id}",
            message=response
        )
```

**性能优化策略：**

1. **连接优化**：
   - WebSocket连接复用
   - 连接心跳检测
   - 自动重连机制
   - 连接池管理

2. **消息处理优化**：
   - 异步消息处理
   - 批量消息处理
   - 消息优先级队列
   - 背压控制

3. **状态管理优化**：
   - 分布式状态同步
   - 状态缓存和持久化
   - 状态变更事件通知

**监控和运维：**

1. **实时监控**：
```python
class SystemMonitor:
    def __init__(self):
        self.metrics = {
            'active_connections': 0,
            'messages_per_second': 0,
            'average_response_time': 0.0,
            'error_rate': 0.0
        }
        self.alerts = AlertManager()
    
    async def collect_metrics(self):
        """收集系统指标"""
        while True:
            # 收集连接数
            self.metrics['active_connections'] = self.get_active_connections()
            
            # 收集消息处理速度
            self.metrics['messages_per_second'] = self.get_message_rate()
            
            # 收集响应时间
            self.metrics['average_response_time'] = self.get_average_response_time()
            
            # 检查告警条件
            await self.check_alerts()
            
            await asyncio.sleep(5)  # 5秒收集一次
    
    async def check_alerts(self):
        """检查告警条件"""
        if self.metrics['active_connections'] > 1000000:
            await self.alerts.send_alert(
                "HIGH_CONNECTION_COUNT",
                f"Active connections: {self.metrics['active_connections']}"
            )
        
        if self.metrics['average_response_time'] > 5.0:
            await self.alerts.send_alert(
                "HIGH_RESPONSE_TIME",
                f"Average response time: {self.metrics['average_response_time']}s"
            )
```

2. **扩容策略**：
   - 基于连接数的水平扩容
   - 基于CPU使用率的自动扩缩容
   - 基于消息队列长度的动态扩容

---

### 1.2 数据存储设计

**问题3：设计一个支持AI Agent的数据库架构，需要考虑对话历史、用户数据、Agent配置等数据的存储需求。**

**参考答案：**
**数据库架构设计：**

```
┌─────────────────────────────────────────────────────────────────┐
│                         应用层                                  │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Agent服务   │  │  用户服务    │  │  分析服务    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         数据访问层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Repository │  │  ORM        │  │  Cache      │              │
│  │  Pattern    │  │  (SQLAlchemy)│  │  (Redis)    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         数据存储层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  PostgreSQL │  │  MongoDB    │  │  Redis      │              │
│  │  (关系数据)  │  │  (文档数据)  │  │  (缓存/状态) │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Elasticsearch│  │  MinIO      │  │  ClickHouse │              │
│  │  (搜索)      │  │  (文件存储)  │  │  (分析)     │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
```

**数据库设计：**

1. **PostgreSQL - 关系数据**：
```sql
-- 用户表
CREATE TABLE users (
    user_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(255) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_login_at TIMESTAMP,
    is_active BOOLEAN DEFAULT true,
    preferences JSONB DEFAULT '{}',
    INDEX idx_users_email (email),
    INDEX idx_users_created_at (created_at)
);

-- Agent配置表
CREATE TABLE agent_configs (
    config_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    agent_name VARCHAR(255) NOT NULL,
    agent_type VARCHAR(100) NOT NULL,
    description TEXT,
    config JSONB NOT NULL,
    created_by UUID REFERENCES users(user_id),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    is_public BOOLEAN DEFAULT false,
    version INTEGER DEFAULT 1,
    INDEX idx_agent_configs_name (agent_name),
    INDEX idx_agent_configs_type (agent_type),
    INDEX idx_agent_configs_created_by (created_by)
);

-- 对话表
CREATE TABLE conversations (
    conversation_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(user_id),
    agent_id UUID REFERENCES agent_configs(config_id),
    title VARCHAR(500),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    status VARCHAR(50) DEFAULT 'active',
    metadata JSONB DEFAULT '{}',
    INDEX idx_conversations_user_id (user_id),
    INDEX idx_conversations_agent_id (agent_id),
    INDEX idx_conversations_created_at (created_at),
    INDEX idx_conversations_status (status)
);

-- 消息表
CREATE TABLE messages (
    message_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID REFERENCES conversations(conversation_id),
    role VARCHAR(50) NOT NULL,  -- 'user', 'assistant', 'system', 'function'
    content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    metadata JSONB DEFAULT '{}',
    tokens_used INTEGER DEFAULT 0,
    INDEX idx_messages_conversation_id (conversation_id),
    INDEX idx_messages_created_at (created_at),
    INDEX idx_messages_role (role)
);

-- 工具调用记录表
CREATE TABLE tool_calls (
    call_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    message_id UUID REFERENCES messages(message_id),
    tool_name VARCHAR(255) NOT NULL,
    parameters JSONB,
    result JSONB,
    execution_time FLOAT,
    status VARCHAR(50) DEFAULT 'pending',
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_tool_calls_message_id (message_id),
    INDEX idx_tool_calls_tool_name (tool_name),
    INDEX idx_tool_calls_status (status),
    INDEX idx_tool_calls_created_at (created_at)
);

-- 用户会话表
CREATE TABLE user_sessions (
    session_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(user_id),
    device_info JSONB,
    ip_address INET,
    user_agent TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMP,
    is_active BOOLEAN DEFAULT true,
    INDEX idx_user_sessions_user_id (user_id),
    INDEX idx_user_sessions_expires_at (expires_at),
    INDEX idx_user_sessions_is_active (is_active)
);

-- 系统配置表
CREATE TABLE system_config (
    key VARCHAR(255) PRIMARY KEY,
    value JSONB NOT NULL,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by UUID REFERENCES users(user_id)
);
```

2. **MongoDB - 文档数据**：
```javascript
// Agent运行时状态
db.agent_runtime_states.createIndex({"agent_id": 1});
db.agent_runtime_states.createIndex({"user_id": 1});
db.agent_runtime_states.createIndex({"last_activity": 1});

// 用户偏好设置
db.user_preferences.createIndex({"user_id": 1});
db.user_preferences.createIndex({"category": 1});

// 文件存储元数据
db.file_metadata.createIndex({"user_id": 1});
db.file_metadata.createIndex({"file_type": 1});
db.file_metadata.createIndex({"created_at": 1});
db.file_metadata.createIndex({"file_hash": 1});

// 分析日志
db.analytics_logs.createIndex({"timestamp": 1});
db.analytics_logs.createIndex({"event_type": 1});
db.analytics_logs.createIndex({"user_id": 1});
db.analytics_logs.createIndex({"agent_id": 1});
```

3. **Redis - 缓存和状态**：
```python
# 缓存键设计
CACHE_KEYS = {
    'user_info': 'user:{user_id}:info',
    'agent_config': 'agent:{agent_id}:config',
    'conversation_context': 'conversation:{conversation_id}:context',
    'session_data': 'session:{session_id}:data',
    'rate_limit': 'rate_limit:{user_id}:{endpoint}',
    'tool_cache': 'tool:{tool_name}:cache:{key}',
    'llm_cache': 'llm:{model}:{hash}',
    'user_sessions': 'user:{user_id}:sessions'
}

# 状态管理
class StateManager:
    def __init__(self, redis_client):
        self.redis = redis_client
    
    async def set_user_state(self, user_id: str, state: dict):
        """设置用户状态"""
        key = CACHE_KEYS['user_info'].format(user_id=user_id)
        await self.redis.setex(key, 3600, json.dumps(state))
    
    async def get_user_state(self, user_id: str) -> Optional[dict]:
        """获取用户状态"""
        key = CACHE_KEYS['user_info'].format(user_id=user_id)
        data = await self.redis.get(key)
        return json.loads(data) if data else None
    
    async def set_conversation_context(self, conversation_id: str, context: dict):
        """设置对话上下文"""
        key = CACHE_KEYS['conversation_context'].format(conversation_id=conversation_id)
        await self.redis.setex(key, 1800, json.dumps(context))  # 30分钟过期
    
    async def get_conversation_context(self, conversation_id: str) -> Optional[dict]:
        """获取对话上下文"""
        key = CACHE_KEYS['conversation_context'].format(conversation_id=conversation_id)
        data = await self.redis.get(key)
        return json.loads(data) if data else None
```

**数据访问层设计：**

1. **Repository模式**：
```python
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update, delete
from typing import Optional, List

class UserRepository:
    def __init__(self, session: AsyncSession):
        self.session = session
    
    async def get_user_by_id(self, user_id: UUID) -> Optional[User]:
        """根据ID获取用户"""
        result = await self.session.execute(
            select(User).where(User.user_id == user_id)
        )
        return result.scalar_one_or_none()
    
    async def get_user_by_email(self, email: str) -> Optional[User]:
        """根据邮箱获取用户"""
        result = await self.session.execute(
            select(User).where(User.email == email)
        )
        return result.scalar_one_or_none()
    
    async def create_user(self, user_data: dict) -> User:
        """创建用户"""
        user = User(**user_data)
        self.session.add(user)
        await self.session.commit()
        await self.session.refresh(user)
        return user
    
    async def update_user(self, user_id: UUID, update_data: dict) -> Optional[User]:
        """更新用户信息"""
        await self.session.execute(
            update(User)
            .where(User.user_id == user_id)
            .values(**update_data)
        )
        await self.session.commit()
        return await self.get_user_by_id(user_id)

class ConversationRepository:
    def __init__(self, session: AsyncSession):
        self.session = session
    
    async def get_conversation(self, conversation_id: UUID) -> Optional[Conversation]:
        """获取对话"""
        result = await self.session.execute(
            select(Conversation).where(Conversation.conversation_id == conversation_id)
        )
        return result.scalar_one_or_none()
    
    async def get_user_conversations(self, user_id: UUID, limit: int = 50, offset: int = 0) -> List[Conversation]:
        """获取用户的对话列表"""
        result = await self.session.execute(
            select(Conversation)
            .where(Conversation.user_id == user_id)
            .order_by(Conversation.updated_at.desc())
            .limit(limit)
            .offset(offset)
        )
        return result.scalars().all()
    
    async def create_conversation(self, conversation_data: dict) -> Conversation:
        """创建对话"""
        conversation = Conversation(**conversation_data)
        self.session.add(conversation)
        await self.session.commit()
        await self.session.refresh(conversation)
        return conversation
```

2. **缓存装饰器**：
```python
import json
import hashlib
from functools import wraps

def cache_result(key_prefix: str, expire: int = 3600):
    """缓存装饰器"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # 生成缓存键
            cache_data = {
                'args': args[1:],  # 跳过self
                'kwargs': kwargs
            }
            cache_str = json.dumps(cache_data, sort_keys=True)
            cache_hash = hashlib.md5(cache_str.encode()).hexdigest()
            cache_key = f"{key_prefix}:{cache_hash}"
            
            # 尝试从缓存获取
            redis_client = args[0].redis  # 假设self有redis属性
            cached_result = await redis_client.get(cache_key)
            if cached_result:
                return json.loads(cached_result)
            
            # 执行函数
            result = await func(*args, **kwargs)
            
            # 缓存结果
            await redis_client.setex(cache_key, expire, json.dumps(result))
            
            return result
        return wrapper
    return decorator

class CachedUserRepository(UserRepository):
    def __init__(self, session: AsyncSession, redis_client):
        super().__init__(session)
        self.redis = redis_client
    
    @cache_result('user_info', 3600)
    async def get_user_by_id(self, user_id: UUID) -> Optional[User]:
        """获取用户信息（带缓存）"""
        return await super().get_user_by_id(user_id)
    
    @cache_result('user_by_email', 3600)
    async def get_user_by_email(self, email: str) -> Optional[User]:
        """根据邮箱获取用户（带缓存）"""
        return await super().get_user_by_email(email)
```

**数据备份和恢复策略：**

1. **备份策略**：
```python
class BackupManager:
    def __init__(self):
        self.postgres_backup = PostgresBackup()
        self.mongo_backup = MongoBackup()
        self.redis_backup = RedisBackup()
    
    async def create_full_backup(self):
        """创建完整备份"""
        backup_id = str(uuid.uuid4())
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 并行备份
        tasks = [
            self.postgres_backup.create_backup(f"postgres_{timestamp}"),
            self.mongo_backup.create_backup(f"mongo_{timestamp}"),
            self.redis_backup.create_backup(f"redis_{timestamp}")
        ]
        
        backup_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 记录备份结果
        await self.record_backup_result(backup_id, backup_results)
        
        return backup_id
    
    async def restore_from_backup(self, backup_id: str):
        """从备份恢复"""
        backup_info = await self.get_backup_info(backup_id)
        
        # 按顺序恢复
        await self.postgres_backup.restore(backup_info['postgres'])
        await self.mongo_backup.restore(backup_info['mongo'])
        await self.redis_backup.restore(backup_info['redis'])
```

2. **数据迁移**：
```python
class DataMigrator:
    def __init__(self):
        self.migrations = []
        self.current_version = 0
    
    def add_migration(self, version: int, description: str, migration_func):
        """添加迁移"""
        self.migrations.append({
            'version': version,
            'description': description,
            'function': migration_func
        })
    
    async def run_migrations(self):
        """运行迁移"""
        for migration in sorted(self.migrations, key=lambda x: x['version']):
            if migration['version'] > self.current_version:
                print(f"Running migration {migration['version']}: {migration['description']}")
                await migration['function']()
                self.current_version = migration['version']
```

---

## 2. 高级系统设计

### 2.1 分布式系统设计

**问题4：设计一个支持多租户的分布式AI Agent系统，需要考虑租户隔离、资源配额和性能优化。**

**参考答案：**
**多租户分布式系统架构：**

```
┌─────────────────────────────────────────────────────────────────┐
│                         网关层                                  │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  API网关    │  │  租户路由    │  │  负载均衡    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         租户管理层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  租户认证    │  │  资源配额    │  │  计费管理    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         业务服务层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Agent服务   │  │  LLM服务    │  │  工具服务   │              │
│  │  (租户隔离)  │  │  (租户隔离)  │  │  (租户隔离)  │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         数据存储层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  租户数据库  │  │  共享数据库  │  │  缓存系统    │              │
│  │  (隔离)      │  │  (共享)      │  │  (命名空间)  │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
```

**核心组件设计：**

1. **租户管理**：
```python
class TenantManager:
    def __init__(self):
        self.tenants: Dict[str, Tenant] = {}
        self.tenant_db_manager = TenantDatabaseManager()
        self.resource_manager = ResourceManager()
    
    async def create_tenant(self, tenant_config: TenantConfig) -> Tenant:
        """创建租户"""
        # 1. 验证租户配置
        await self.validate_tenant_config(tenant_config)
        
        # 2. 创建租户数据库
        db_config = await self.tenant_db_manager.create_tenant_database(
            tenant_config.tenant_id
        )
        
        # 3. 初始化租户资源
        await self.resource_manager.allocate_tenant_resources(
            tenant_config.tenant_id,
            tenant_config.resource_quota
        )
        
        # 4. 创建租户实例
        tenant = Tenant(
            tenant_id=tenant_config.tenant_id,
            name=tenant_config.name,
            config=tenant_config,
            db_config=db_config,
            created_at=datetime.now()
        )
        
        self.tenants[tenant_config.tenant_id] = tenant
        
        # 5. 初始化租户数据
        await self.initialize_tenant_data(tenant)
        
        return tenant
    
    async def get_tenant(self, tenant_id: str) -> Optional[Tenant]:
        """获取租户"""
        return self.tenants.get(tenant_id)
    
    async def validate_tenant_access(self, tenant_id: str, user_id: str) -> bool:
        """验证租户访问权限"""
        tenant = await self.get_tenant(tenant_id)
        if not tenant:
            return False
        
        # 检查用户是否属于该租户
        return await self.check_user_tenant_membership(user_id, tenant_id)

class Tenant:
    def __init__(self, tenant_id: str, name: str, config: TenantConfig, 
                 db_config: DatabaseConfig, created_at: datetime):
        self.tenant_id = tenant_id
        self.name = name
        self.config = config
        self.db_config = db_config
        self.created_at = created_at
        self.status = 'active'
        
        # 租户特定的组件
        self.agent_factory = TenantAgentFactory(self)
        self.cache = TenantCache(self)
        self.metrics = TenantMetrics(self)
```

2. **资源配额管理**：
```python
class ResourceManager:
    def __init__(self):
        self.quotas: Dict[str, ResourceQuota] = {}
        self.usage: Dict[str, ResourceUsage] = {}
        self.enforcer = ResourceEnforcer()
    
    async def allocate_tenant_resources(self, tenant_id: str, quota: ResourceQuota):
        """分配租户资源"""
        self.quotas[tenant_id] = quota
        self.usage[tenant_id] = ResourceUsage()
        
        # 初始化资源限制器
        await self.enforcer.initialize_tenant_limits(tenant_id, quota)
    
    async def check_resource_limit(self, tenant_id: str, resource_type: str, amount: int) -> bool:
        """检查资源限制"""
        quota = self.quotas.get(tenant_id)
        usage = self.usage.get(tenant_id)
        
        if not quota or not usage:
            return False
        
        # 检查是否超出配额
        current_usage = getattr(usage, resource_type, 0)
        limit = getattr(quota, resource_type, 0)
        
        return current_usage + amount <= limit
    
    async def record_resource_usage(self, tenant_id: str, resource_type: str, amount: int):
        """记录资源使用"""
        if tenant_id in self.usage:
            current_usage = getattr(self.usage[tenant_id], resource_type, 0)
            setattr(self.usage[tenant_id], resource_type, current_usage + amount)
    
    async def get_tenant_usage(self, tenant_id: str) -> ResourceUsage:
        """获取租户资源使用情况"""
        return self.usage.get(tenant_id, ResourceUsage())

class ResourceQuota:
    def __init__(self,
                 max_concurrent_requests: int = 100,
                 max_tokens_per_month: int = 1000000,
                 max_storage_size: int = 10 * 1024 * 1024 * 1024,  # 10GB
                 max_agents: int = 10,
                 max_users: int = 100):
        self.max_concurrent_requests = max_concurrent_requests
        self.max_tokens_per_month = max_tokens_per_month
        self.max_storage_size = max_storage_size
        self.max_agents = max_agents
        self.max_users = max_users

class ResourceUsage:
    def __init__(self):
        self.concurrent_requests = 0
        self.tokens_used_this_month = 0
        self.storage_used = 0
        self.agents_created = 0
        self.users_count = 0
```

3. **租户隔离的服务层**：
```python
class TenantAgentService:
    def __init__(self, tenant: Tenant):
        self.tenant = tenant
        self.db_session = TenantDBSession(tenant.db_config)
        self.cache = tenant.cache
        self.resource_manager = ResourceManager()
    
    async def create_agent(self, agent_config: AgentConfig) -> Agent:
        """创建Agent"""
        # 1. 检查资源配额
        if not await self.resource_manager.check_resource_limit(
            self.tenant.tenant_id, 'max_agents', 1
        ):
            raise ResourceQuotaExceededError("Maximum agents limit reached")
        
        # 2. 创建Agent实例
        agent = await self.tenant.agent_factory.create_agent(agent_config)
        
        # 3. 保存到租户数据库
        await self.save_agent_to_db(agent)
        
        # 4. 记录资源使用
        await self.resource_manager.record_resource_usage(
            self.tenant.tenant_id, 'agents_created', 1
        )
        
        return agent
    
    async def process_message(self, request: AgentRequest) -> AgentResponse:
        """处理消息"""
        # 1. 检查并发请求限制
        if not await self.resource_manager.check_resource_limit(
            self.tenant.tenant_id, 'max_concurrent_requests', 1
        ):
            raise ResourceQuotaExceededError("Concurrent requests limit reached")
        
        # 2. 获取Agent实例
        agent = await self.get_agent(request.agent_id)
        
        # 3. 处理消息
        response = await agent.process_message(
            request.message,
            request.conversation_id
        )
        
        # 4. 记录token使用
        if response.tokens_used:
            await self.resource_manager.record_resource_usage(
                self.tenant.tenant_id, 'tokens_used_this_month', response.tokens_used
            )
        
        return response

class TenantLLMService:
    def __init__(self, tenant: Tenant):
        self.tenant = tenant
        self.llm_providers = TenantLLMProviders(tenant)
        self.cache = tenant.cache
    
    async def chat(self, request: ChatRequest) -> ChatResponse:
        """LLM聊天"""
        # 1. 检查token配额
        estimated_tokens = self.estimate_tokens(request.messages)
        if not await self.resource_manager.check_resource_limit(
            self.tenant.tenant_id, 'tokens_used_this_month', estimated_tokens
        ):
            raise ResourceQuotaExceededError("Token quota exceeded")
        
        # 2. 选择LLM提供商
        provider = await self.llm_providers.select_provider(request.model)
        
        # 3. 调用LLM
        response = await provider.chat(request)
        
        # 4. 记录实际token使用
        await self.resource_manager.record_resource_usage(
            self.tenant.tenant_id, 'tokens_used_this_month', response.tokens_used
        )
        
        return response
```

4. **租户数据库管理**：
```python
class TenantDatabaseManager:
    def __init__(self):
        self.connection_pool = ConnectionPool()
        self.schema_manager = SchemaManager()
    
    async def create_tenant_database(self, tenant_id: str) -> DatabaseConfig:
        """创建租户数据库"""
        # 1. 创建数据库
        db_name = f"tenant_{tenant_id}"
        await self.create_database(db_name)
        
        # 2. 创建用户
        username = f"tenant_{tenant_id}_user"
        password = generate_secure_password()
        await self.create_database_user(db_name, username, password)
        
        # 3. 初始化schema
        await self.schema_manager.initialize_tenant_schema(db_name, username)
        
        return DatabaseConfig(
            database_name=db_name,
            username=username,
            password=password,
            host=self.get_database_host()
        )
    
    async def get_tenant_session(self, tenant_id: str) -> AsyncSession:
        """获取租户数据库会话"""
        tenant = await self.get_tenant(tenant_id)
        if not tenant:
            raise TenantNotFoundError(tenant_id)
        
        return await self.connection_pool.get_session(tenant.db_config)

class SchemaManager:
    async def initialize_tenant_schema(self, db_name: str, username: str):
        """初始化租户数据库schema"""
        # 创建租户特定的表
        tables = [
            """
            CREATE TABLE tenant_agents (
                agent_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                name VARCHAR(255) NOT NULL,
                config JSONB NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,
            """
            CREATE TABLE tenant_conversations (
                conversation_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                agent_id UUID REFERENCES tenant_agents(agent_id),
                title VARCHAR(500),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,
            """
            CREATE TABLE tenant_messages (
                message_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                conversation_id UUID REFERENCES tenant_conversations(conversation_id),
                role VARCHAR(50) NOT NULL,
                content TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """
        ]
        
        for table_sql in tables:
            await self.execute_sql(db_name, username, table_sql)
```

**监控和计费：**

1. **租户监控**：
```python
class TenantMonitor:
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.alert_manager = AlertManager()
    
    async def collect_tenant_metrics(self, tenant_id: str) -> TenantMetrics:
        """收集租户指标"""
        # 资源使用情况
        resource_usage = await self.resource_manager.get_tenant_usage(tenant_id)
        
        # 性能指标
        performance_metrics = await self.metrics_collector.get_performance_metrics(tenant_id)
        
        # 错误率
        error_rate = await self.metrics_collector.get_error_rate(tenant_id)
        
        # 用户活跃度
        user_activity = await self.metrics_collector.get_user_activity(tenant_id)
        
        return TenantMetrics(
            resource_usage=resource_usage,
            performance=performance_metrics,
            error_rate=error_rate,
            user_activity=user_activity,
            collected_at=datetime.now()
        )
    
    async def check_tenant_alerts(self, tenant_id: str):
        """检查租户告警"""
        metrics = await self.collect_tenant_metrics(tenant_id)
        
        # 检查资源使用率
        for resource_type, usage in metrics.resource_usage.__dict__.items():
            quota = getattr(self.quotas.get(tenant_id), resource_type, 0)
            if quota > 0:
                usage_rate = usage / quota
                if usage_rate > 0.9:  # 90%使用率
                    await self.alert_manager.send_alert(
                        tenant_id,
                        f"High {resource_type} usage: {usage_rate:.1%}"
                    )
        
        # 检查错误率
        if metrics.error_rate > 0.1:  # 10%错误率
            await self.alert_manager.send_alert(
                tenant_id,
                f"High error rate: {metrics.error_rate:.1%}"
            )
```

2. **计费系统**：
```python
class BillingManager:
    def __init__(self):
        self.rate_plans = RatePlanManager()
        self.usage_tracker = UsageTracker()
        self.invoice_generator = InvoiceGenerator()
    
    async def calculate_monthly_bill(self, tenant_id: str, year: int, month: int) -> Invoice:
        """计算月度账单"""
        # 获取租户费率计划
        rate_plan = await self.rate_plans.get_tenant_rate_plan(tenant_id)
        
        # 获取使用情况
        usage = await self.usage_tracker.get_monthly_usage(tenant_id, year, month)
        
        # 计算费用
        line_items = []
        
        # Token费用
        if usage.tokens_used > 0:
            token_cost = usage.tokens_used * rate_plan.token_rate
            line_items.append(LineItem(
                description="Token usage",
                quantity=usage.tokens_used,
                unit_price=rate_plan.token_rate,
                total_cost=token_cost
            ))
        
        # 存储费用
        if usage.storage_used > 0:
            storage_gb = usage.storage_used / (1024 * 1024 * 1024)
            storage_cost = storage_gb * rate_plan.storage_rate_per_gb
            line_items.append(LineItem(
                description="Storage usage",
                quantity=storage_gb,
                unit_price=rate_plan.storage_rate_per_gb,
                total_cost=storage_cost
            ))
        
        # Agent费用
        if usage.active_agents > 0:
            agent_cost = usage.active_agents * rate_plan.agent_monthly_rate
            line_items.append(LineItem(
                description="Active agents",
                quantity=usage.active_agents,
                unit_price=rate_plan.agent_monthly_rate,
                total_cost=agent_cost
            ))
        
        # 生成发票
        total_cost = sum(item.total_cost for item in line_items)
        return Invoice(
            tenant_id=tenant_id,
            billing_period=f"{year}-{month:02d}",
            line_items=line_items,
            total_cost=total_cost,
            generated_at=datetime.now()
        )
```

---

### 2.2 性能优化设计

**问题5：设计一个高性能的AI Agent系统，需要考虑缓存策略、并发处理、资源优化等方面。**

**参考答案：**
**高性能系统架构：**

```
┌─────────────────────────────────────────────────────────────────┐
│                         客户端层                                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Web应用    │  │  移动应用   │  │  API客户端   │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         CDN层                                  │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  静态资源    │  │  API缓存    │  │  DDoS防护   │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         应用层                                  │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  API网关    │  │  负载均衡    │  │  限流熔断    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         服务层                                  │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Agent服务   │  │  LLM服务    │  │  工具服务   │              │
│  │  (连接池)    │  │  (连接池)    │  │  (沙箱)     │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         缓存层                                  │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  内存缓存    │  │  分布式缓存  │  │  对象缓存    │              │
│  │  (LRU)       │  │  (Redis)    │  │  (Memcached)│              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         数据层                                  │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  主数据库    │  │  从数据库    │  │  分析数据库  │              │
│  │  (读写分离)  │  │  (只读)      │  │  (列存储)    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
```

**性能优化策略：**

1. **多级缓存系统**：
```python
class MultiLevelCache:
    def __init__(self):
        self.l1_cache = MemoryCache(max_size=10000, ttl=300)  # 5分钟
        self.l2_cache = RedisCache(ttl=3600)  # 1小时
        self.l3_cache = DatabaseCache(ttl=86400)  # 24小时
        
        self.stats = CacheStats()
        self.warmer = CacheWarmer()
    
    async def get(self, key: str) -> Optional[Any]:
        """多级缓存获取"""
        start_time = time.time()
        
        # L1: 内存缓存
        result = await self.l1_cache.get(key)
        if result is not None:
            self.stats.record_hit('l1')
            return result
        
        # L2: Redis缓存
        result = await self.l2_cache.get(key)
        if result is not None:
            # 回填L1缓存
            await self.l1_cache.set(key, result)
            self.stats.record_hit('l2')
            return result
        
        # L3: 数据库缓存
        result = await self.l3_cache.get(key)
        if result is not None:
            # 回填L1和L2缓存
            await self.l1_cache.set(key, result)
            await self.l2_cache.set(key, result)
            self.stats.record_hit('l3')
            return result
        
        self.stats.record_miss()
        return None
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """多级缓存设置"""
        # 并行设置所有级别的缓存
        tasks = [
            self.l1_cache.set(key, value, ttl),
            self.l2_cache.set(key, value, ttl),
            self.l3_cache.set(key, value, ttl)
        ]
        
        await asyncio.gather(*tasks, return_exceptions=True)
    
    async def get_or_set(self, key: str, factory: Callable, ttl: Optional[int] = None) -> Any:
        """获取或设置缓存"""
        result = await self.get(key)
        if result is not None:
            return result
        
        # 防止缓存击穿
        async with self._get_lock(key):
            # 双重检查
            result = await self.get(key)
            if result is not None:
                return result
            
            # 生成数据
            result = await factory()
            await self.set(key, result, ttl)
            return result
    
    async def _get_lock(self, key: str) -> asyncio.Lock:
        """获取分布式锁"""
        # 使用Redis实现分布式锁
        lock_key = f"lock:{key}"
        return await self._acquire_lock(lock_key)

class CacheWarmer:
    def __init__(self):
        self.warmup_queue = asyncio.Queue()
        self.workers = []
    
    async def start(self, worker_count: int = 3):
        """启动缓存预热工作器"""
        for i in range(worker_count):
            worker = asyncio.create_task(self._warmup_worker(f"worker_{i}"))
            self.workers.append(worker)
    
    async def add_warmup_task(self, key: str, factory: Callable, priority: int = 0):
        """添加预热任务"""
        await self.warmup_queue.put((priority, key, factory))
    
    async def _warmup_worker(self, worker_id: str):
        """缓存预热工作器"""
        while True:
            try:
                priority, key, factory = await self.warmup_queue.get()
                
                # 执行预热
                try:
                    result = await factory()
                    await self.cache.set(key, result)
                    print(f"Worker {worker_id}: Warmed up cache for key {key}")
                except Exception as e:
                    print(f"Worker {worker_id}: Failed to warm up cache for key {key}: {e}")
                
            except Exception as e:
                print(f"Worker {worker_id}: Error {e}")
                await asyncio.sleep(1)
```

2. **连接池优化**：
```python
class OptimizedConnectionPool:
    def __init__(self, 
                 min_connections: int = 5,
                 max_connections: int = 100,
                 max_idle_time: float = 300.0):
        self.min_connections = min_connections
        self.max_connections = max_connections
        self.max_idle_time = max_idle_time
        
        self.connections: Dict[str, List[Connection]] = {}
        self.connection_stats: Dict[str, ConnectionStats] = {}
        self.lock = asyncio.Lock()
        
        # 启动连接维护任务
        self.maintenance_task = asyncio.create_task(self._maintain_connections())
    
    async def get_connection(self, connection_key: str) -> Connection:
        """获取连接"""
        async with self.lock:
            if connection_key not in self.connections:
                self.connections[connection_key] = []
                self.connection_stats[connection_key] = ConnectionStats()
            
            # 尝试获取空闲连接
            for i, conn in enumerate(self.connections[connection_key]):
                if not conn.in_use and conn.is_healthy():
                    conn.in_use = True
                    conn.last_used = time.time()
                    self.connection_stats[connection_key].record_acquire()
                    return conn
            
            # 创建新连接
            if len(self.connections[connection_key]) < self.max_connections:
                new_conn = await self._create_connection(connection_key)
                new_conn.in_use = True
                self.connections[connection_key].append(new_conn)
                self.connection_stats[connection_key].record_create()
                return new_conn
            
            # 等待连接释放
            raise ConnectionPoolExhaustedError(f"Connection pool exhausted for {connection_key}")
    
    async def release_connection(self, connection_key: str, connection: Connection):
        """释放连接"""
        async with self.lock:
            connection.in_use = False
            connection.last_used = time.time()
            self.connection_stats[connection_key].record_release()
    
    async def _create_connection(self, connection_key: str) -> Connection:
        """创建新连接"""
        # 根据连接键创建不同类型的连接
        if connection_key.startswith('http://') or connection_key.startswith('https://'):
            return await self._create_http_connection(connection_key)
        elif connection_key.startswith('postgres://'):
            return await self._create_db_connection(connection_key)
        else:
            raise ValueError(f"Unsupported connection type: {connection_key}")
    
    async def _maintain_connections(self):
        """维护连接池"""
        while True:
            try:
                await asyncio.sleep(60)  # 每分钟维护一次
                
                async with self.lock:
                    for connection_key, connections in self.connections.items():
                        # 清理过期连接
                        connections_to_remove = []
                        for conn in connections:
                            if (not conn.in_use and 
                                time.time() - conn.last_used > self.max_idle_time and
                                len(connections) > self.min_connections):
                                connections_to_remove.append(conn)
                        
                        for conn in connections_to_remove:
                            await conn.close()
                            connections.remove(conn)
                            self.connection_stats[connection_key].record_close()
                        
                        # 确保最小连接数
                        while len(connections) < self.min_connections:
                            new_conn = await self._create_connection(connection_key)
                            connections.append(new_conn)
                            self.connection_stats[connection_key].record_create()
            
            except Exception as e:
                print(f"Connection maintenance error: {e}")
                await asyncio.sleep(60)

class HTTPConnectionPool(OptimizedConnectionPool):
    async def _create_http_connection(self, url: str) -> HTTPConnection:
        """创建HTTP连接"""
        connector = aiohttp.TCPConnector(
            limit=0,  # 无限制
            ttl_dns_cache=300,
            use_dns_cache=True,
            keepalive_timeout=30,
            enable_cleanup_closed=True
        )
        
        session = aiohttp.ClientSession(
            connector=connector,
            timeout=aiohttp.ClientTimeout(total=30)
        )
        
        return HTTPConnection(session, url)

class DatabaseConnectionPool(OptimizedConnectionPool):
    async def _create_db_connection(self, connection_string: str) -> DatabaseConnection:
        """创建数据库连接"""
        engine = create_async_engine(
            connection_string,
            pool_size=10,
            max_overflow=20,
            pool_pre_ping=True,
            pool_recycle=3600
        )
        
        return DatabaseConnection(engine, connection_string)
```

3. **异步处理优化**：
```python
class AsyncProcessor:
    def __init__(self, max_concurrent_tasks: int = 100):
        self.max_concurrent_tasks = max_concurrent_tasks
        self.semaphore = asyncio.Semaphore(max_concurrent_tasks)
        self.task_queue = asyncio.PriorityQueue()
        self.active_tasks = 0
        self.stats = ProcessorStats()
        
        # 启动处理器
        self.processor_task = asyncio.create_task(self._process_tasks())
    
    async def submit_task(self, 
                         task: Callable, 
                         args: tuple = (), 
                         kwargs: dict = None,
                         priority: int = 0) -> asyncio.Future:
        """提交任务"""
        future = asyncio.Future()
        task_wrapper = TaskWrapper(
            task=task,
            args=args,
            kwargs=kwargs or {},
            future=future,
            priority=priority,
            submitted_at=time.time()
        )
        
        await self.task_queue.put(task_wrapper)
        return future
    
    async def _process_tasks(self):
        """处理任务队列"""
        while True:
            try:
                task_wrapper = await self.task_queue.get()
                
                async with self.semaphore:
                    self.active_tasks += 1
                    start_time = time.time()
                    
                    try:
                        # 执行任务
                        result = await task_wrapper.task(
                            *task_wrapper.args, 
                            **task_wrapper.kwargs
                        )
                        
                        # 设置结果
                        task_wrapper.future.set_result(result)
                        
                        # 记录统计
                        execution_time = time.time() - start_time
                        self.stats.record_success(execution_time)
                        
                    except Exception as e:
                        # 设置异常
                        task_wrapper.future.set_exception(e)
                        
                        # 记录错误
                        execution_time = time.time() - start_time
                        self.stats.record_error(execution_time)
                    
                    finally:
                        self.active_tasks -= 1
                        
            except Exception as e:
                print(f"Task processing error: {e}")
                await asyncio.sleep(1)
    
    async def batch_process(self, tasks: List[TaskWrapper]) -> List[Any]:
        """批量处理任务"""
        futures = []
        for task in tasks:
            future = await self.submit_task(
                task.task, 
                task.args, 
                task.kwargs, 
                task.priority
            )
            futures.append(future)
        
        # 等待所有任务完成
        results = await asyncio.gather(*futures, return_exceptions=True)
        return results

class StreamingProcessor:
    def __init__(self, batch_size: int = 10, max_wait_time: float = 1.0):
        self.batch_size = batch_size
        self.max_wait_time = max_wait_time
        self.pending_items = []
        self.last_batch_time = time.time()
        self.processor = AsyncProcessor()
    
    async def add_item(self, item: Any, priority: int = 0) -> Optional[List[Any]]:
        """添加项目到批处理器"""
        self.pending_items.append((priority, time.time(), item))
        
        # 检查是否可以处理批次
        if (len(self.pending_items) >= self.batch_size or 
            time.time() - self.last_batch_time >= self.max_wait_time):
            return await self._process_batch()
        
        return None
    
    async def _process_batch(self) -> List[Any]:
        """处理批次"""
        if not self.pending_items:
            return []
        
        # 排序并提取项目
        self.pending_items.sort(key=lambda x: (x[0], x[1]))
        batch_items = [item for _, _, item in self.pending_items]
        self.pending_items.clear()
        self.last_batch_time = time.time()
        
        # 批量处理
        tasks = [
            TaskWrapper(
                task=self._process_single_item,
                args=(item,),
                kwargs={},
                future=None,
                priority=0,
                submitted_at=time.time()
            )
            for item in batch_items
        ]
        
        return await self.processor.batch_process(tasks)
    
    async def _process_single_item(self, item: Any) -> Any:
        """处理单个项目"""
        # 这里实现具体的处理逻辑
        return item
```

4. **资源监控和自适应优化**：
```python
class ResourceMonitor:
    def __init__(self):
        self.metrics = {}
        self.thresholds = {}
        self.optimizers = {}
        self.running = False
    
    async def start_monitoring(self):
        """启动监控"""
        self.running = True
        asyncio.create_task(self._monitor_loop())
    
    async def _monitor_loop(self):
        """监控循环"""
        while self.running:
            try:
                # 收集指标
                await self._collect_metrics()
                
                # 检查阈值
                await self._check_thresholds()
                
                # 执行优化
                await self._optimize_resources()
                
                await asyncio.sleep(10)  # 10秒监控间隔
                
            except Exception as e:
                print(f"Monitoring error: {e}")
                await asyncio.sleep(10)
    
    async def _collect_metrics(self):
        """收集系统指标"""
        # CPU使用率
        cpu_percent = psutil.cpu_percent(interval=1)
        self.metrics['cpu_percent'] = cpu_percent
        
        # 内存使用率
        memory = psutil.virtual_memory()
        self.metrics['memory_percent'] = memory.percent
        
        # 磁盘使用率
        disk = psutil.disk_usage('/')
        self.metrics['disk_percent'] = disk.percent
        
        # 网络IO
        network = psutil.net_io_counters()
        self.metrics['network_bytes_sent'] = network.bytes_sent
        self.metrics['network_bytes_recv'] = network.bytes_recv
    
    async def _check_thresholds(self):
        """检查阈值"""
        if self.metrics.get('cpu_percent', 0) > 80:
            await self._trigger_alert('high_cpu', self.metrics['cpu_percent'])
        
        if self.metrics.get('memory_percent', 0) > 85:
            await self._trigger_alert('high_memory', self.metrics['memory_percent'])
        
        if self.metrics.get('disk_percent', 0) > 90:
            await self._trigger_alert('high_disk', self.metrics['disk_percent'])
    
    async def _optimize_resources(self):
        """优化资源"""
        # 基于CPU使用率调整并发度
        cpu_percent = self.metrics.get('cpu_percent', 0)
        if cpu_percent > 70:
            await self._reduce_concurrency()
        elif cpu_percent < 30:
            await self._increase_concurrency()
        
        # 基于内存使用率清理缓存
        memory_percent = self.metrics.get('memory_percent', 0)
        if memory_percent > 80:
            await self._cleanup_cache()
    
    async def _reduce_concurrency(self):
        """减少并发度"""
        # 调整连接池大小
        for pool in self.connection_pools:
            await pool.reduce_size()
        
        # 调整处理器并发度
        for processor in self.processors:
            await processor.reduce_concurrency()
    
    async def _increase_concurrency(self):
        """增加并发度"""
        # 调整连接池大小
        for pool in self.connection_pools:
            await pool.increase_size()
        
        # 调整处理器并发度
        for processor in self.processors:
            await processor.increase_concurrency()
    
    async def _cleanup_cache(self):
        """清理缓存"""
        # 清理内存缓存
        for cache in self.caches:
            await cache.cleanup_expired()
        
        # 清理临时文件
        await self._cleanup_temp_files()
```

---

## 3. 系统集成设计

### 3.1 微服务架构

**问题6：设计一个基于微服务架构的AI Agent平台，包含服务拆分、服务发现、负载均衡等设计。**

**参考答案：**
**微服务架构设计：**

```
┌─────────────────────────────────────────────────────────────────┐
│                         API网关                                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  路由转发    │  │  认证授权    │  │  限流熔断    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         服务发现                                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Consul     │  │  健康检查    │  │  服务注册    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         核心服务层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Agent服务   │  │  LLM服务    │  │  工具服务   │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  用户服务    │  │  会话服务    │  │  文件服务    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         支撑服务层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  消息队列    │  │  缓存服务    │  │  配置中心    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  监控服务    │  │  日志服务    │  │  链路追踪    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         数据存储层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  PostgreSQL │  │  MongoDB    │  │  Redis      │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Elasticsearch│  │  MinIO      │  │  Kafka      │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
```

**核心服务设计：**

1. **服务注册和发现**：
```python
class ServiceRegistry:
    def __init__(self, consul_host: str = 'localhost', consul_port: int = 8500):
        self.consul_client = consul.Consul(host=consul_host, port=consul_port)
        self.local_services: Dict[str, ServiceInstance] = {}
        self.health_checker = HealthChecker()
    
    async def register_service(self, service_config: ServiceConfig):
        """注册服务"""
        service_id = f"{service_config.name}-{service_config.instance_id}"
        
        # 注册到Consul
        await self.consul_client.agent.service.register(
            name=service_config.name,
            service_id=service_id,
            address=service_config.address,
            port=service_config.port,
            tags=service_config.tags,
            check=consul.Check.http(
                f"http://{service_config.address}:{service_config.port}/health",
                interval="10s",
                timeout="5s"
            )
        )
        
        # 本地缓存
        self.local_services[service_id] = ServiceInstance(
            id=service_id,
            name=service_config.name,
            address=service_config.address,
            port=service_config.port,
            tags=service_config.tags,
            registered_at=datetime.now()
        )
        
        # 启动健康检查
        await self.health_checker.start_health_check(service_id, service_config)
    
    async def discover_service(self, service_name: str) -> List[ServiceInstance]:
        """发现服务"""
        # 从Consul获取服务实例
        _, services = await self.consul_client.health.service(
            service_name, passing=True
        )
        
        instances = []
        for service in services:
            instances.append(ServiceInstance(
                id=service['Service']['ID'],
                name=service['Service']['Service'],
                address=service['Service']['Address'],
                port=service['Service']['Port'],
                tags=service['Service']['Tags'],
                registered_at=datetime.now()
            ))
        
        return instances
    
    async def deregister_service(self, service_id: str):
        """注销服务"""
        await self.consul_client.agent.service.deregister(service_id)
        
        if service_id in self.local_services:
            del self.local_services[service_id]
        
        await self.health_checker.stop_health_check(service_id)

class LoadBalancer:
    def __init__(self, service_registry: ServiceRegistry):
        self.service_registry = service_registry
        self.strategies = {
            'round_robin': RoundRobinStrategy(),
            'least_connections': LeastConnectionsStrategy(),
            'weighted': WeightedStrategy()
        }
        self.current_strategy = 'round_robin'
    
    async def select_instance(self, service_name: str) -> ServiceInstance:
        """选择服务实例"""
        instances = await self.service_registry.discover_service(service_name)
        
        if not instances:
            raise ServiceUnavailableError(f"No available instances for service: {service_name}")
        
        strategy = self.strategies[self.current_strategy]
        return await strategy.select(instances)
    
    def set_strategy(self, strategy_name: str):
        """设置负载均衡策略"""
        if strategy_name in self.strategies:
            self.current_strategy = strategy_name

class RoundRobinStrategy:
    def __init__(self):
        self.counters = {}
    
    async def select(self, instances: List[ServiceInstance]) -> ServiceInstance:
        """轮询选择"""
        service_name = instances[0].name
        if service_name not in self.counters:
            self.counters[service_name] = 0
        
        index = self.counters[service_name] % len(instances)
        self.counters[service_name] += 1
        
        return instances[index]

class LeastConnectionsStrategy:
    def __init__(self):
        self.connection_counts = {}
    
    async def select(self, instances: List[ServiceInstance]) -> ServiceInstance:
        """最少连接选择"""
        # 获取每个实例的连接数
        instance_counts = []
        for instance in instances:
            count = self.connection_counts.get(instance.id, 0)
            instance_counts.append((instance, count))
        
        # 选择连接数最少的实例
        instance_counts.sort(key=lambda x: x[1])
        return instance_counts[0][0]
```

2. **API网关**：
```python
class APIGateway:
    def __init__(self):
        self.service_registry = ServiceRegistry()
        self.load_balancer = LoadBalancer(self.service_registry)
        self.rate_limiter = RateLimiter()
        self.circuit_breaker = CircuitBreaker()
        self.auth_manager = AuthenticationManager()
        self.router = Router()
    
    async def initialize(self):
        """初始化网关"""
        # 配置路由
        await self._setup_routes()
        
        # 启动中间件
        await self._setup_middleware()
    
    async def handle_request(self, request: Request) -> Response:
        """处理请求"""
        try:
            # 1. 认证
            await self.auth_manager.authenticate(request)
            
            # 2. 限流
            await self.rate_limiter.check_limit(request)
            
            # 3. 路由到服务
            service_name, path = await self.router.route(request)
            
            # 4. 负载均衡选择实例
            service_instance = await self.load_balancer.select_instance(service_name)
            
            # 5. 熔断器检查
            if not await self.circuit_breaker.is_available(service_name):
                raise ServiceUnavailableError(f"Service {service_name} is unavailable")
            
            # 6. 转发请求
            response = await self._forward_request(service_instance, path, request)
            
            # 7. 记录成功
            await self.circuit_breaker.record_success(service_name)
            
            return response
            
        except Exception as e:
            # 记录失败
            if 'service_name' in locals():
                await self.circuit_breaker.record_failure(service_name)
            
            return await self._handle_error(e)
    
    async def _forward_request(self, 
                              service_instance: ServiceInstance, 
                              path: str, 
                              request: Request) -> Response:
        """转发请求到服务实例"""
        url = f"http://{service_instance.address}:{service_instance.port}{path}"
        
        async with aiohttp.ClientSession() as session:
            async with session.request(
                method=request.method,
                url=url,
                headers=dict(request.headers),
                data=await request.body()
            ) as response:
                return Response(
                    status=response.status,
                    headers=dict(response.headers),
                    body=await response.read()
                )

class CircuitBreaker:
    def __init__(self):
        self.circuit_states = {}  # 服务名 -> 熔断器状态
        self.failure_thresholds = {}  # 服务名 -> 失败阈值
        self.recovery_timeouts = {}  # 服务名 -> 恢复超时
    
    async def is_available(self, service_name: str) -> bool:
        """检查服务是否可用"""
        state = self.circuit_states.get(service_name)
        if not state:
            return True
        
        if state['state'] == 'CLOSED':
            return True
        elif state['state'] == 'OPEN':
            # 检查是否可以尝试恢复
            if time.time() - state['last_failure_time'] > state['recovery_timeout']:
                state['state'] = 'HALF_OPEN'
                return True
            return False
        else:  # HALF_OPEN
            return True
    
    async def record_success(self, service_name: str):
        """记录成功"""
        state = self.circuit_states.get(service_name)
        if state:
            if state['state'] == 'HALF_OPEN':
                state['state'] = 'CLOSED'
                state['failure_count'] = 0
            elif state['state'] == 'CLOSED':
                state['failure_count'] = 0
    
    async def record_failure(self, service_name: str):
        """记录失败"""
        if service_name not in self.circuit_states:
            self.circuit_states[service_name] = {
                'state': 'CLOSED',
                'failure_count': 0,
                'last_failure_time': 0,
                'recovery_timeout': 60,  # 60秒恢复超时
                'failure_threshold': 5  # 5次失败后熔断
            }
        
        state = self.circuit_states[service_name]
        state['failure_count'] += 1
        state['last_failure_time'] = time.time()
        
        if (state['state'] == 'CLOSED' and 
            state['failure_count'] >= state['failure_threshold']):
            state['state'] = 'OPEN'
```

3. **配置中心**：
```python
class ConfigCenter:
    def __init__(self, consul_host: str = 'localhost', consul_port: int = 8500):
        self.consul_client = consul.Consul(host=consul_host, port=consul_port)
        self.local_cache = {}
        self.watchers = {}
    
    async def get_config(self, key: str, default: Any = None) -> Any:
        """获取配置"""
        # 先从本地缓存获取
        if key in self.local_cache:
            return self.local_cache[key]
        
        # 从Consul获取
        try:
            index, data = await self.consul_client.kv.get(key)
            if data:
                value = json.loads(data['Value'].decode())
                self.local_cache[key] = value
                return value
        except Exception as e:
            print(f"Failed to get config {key}: {e}")
        
        return default
    
    async def set_config(self, key: str, value: Any):
        """设置配置"""
        await self.consul_client.kv.put(key, json.dumps(value))
        self.local_cache[key] = value
        
        # 通知观察者
        await self._notify_watchers(key, value)
    
    async def watch_config(self, key: str, callback: Callable):
        """监听配置变化"""
        if key not in self.watchers:
            self.watchers[key] = []
        self.watchers[key].append(callback)
    
    async def _notify_watchers(self, key: str, value: Any):
        """通知观察者"""
        if key in self.watchers:
            for callback in self.watchers[key]:
                try:
                    await callback(key, value)
                except Exception as e:
                    print(f"Watcher callback error: {e}")

class ServiceConfig:
    def __init__(self, config_center: ConfigCenter):
        self.config_center = config_center
    
    async def get_service_config(self, service_name: str) -> ServiceConfigData:
        """获取服务配置"""
        config_key = f"services/{service_name}/config"
        config_data = await self.config_center.get_config(config_key)
        
        if not config_data:
            config_data = self._get_default_config(service_name)
            await self.config_center.set_config(config_key, config_data)
        
        return ServiceConfigData(**config_data)
    
    async def watch_service_config(self, service_name: str, callback: Callable):
        """监听服务配置变化"""
        config_key = f"services/{service_name}/config"
        await self.config_center.watch_config(config_key, callback)
```

---

### 3.2 消息队列设计

**问题7：设计一个基于消息队列的异步处理系统，支持消息路由、死信队列、重试机制等。**

**参考答案：**
**消息队列系统架构：**

```
┌─────────────────────────────────────────────────────────────────┐
│                         消息生产者                              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Agent服务   │  │  API网关    │  │  定时任务    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         消息路由层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  主题路由    │  │  队列路由    │  │  条件路由    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         消息队列层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  主队列      │  │  重试队列    │  │  死信队列    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  延迟队列    │  │  优先级队列  │  │  批处理队列  │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
┌─────────────────────────────────────────────────────────────────┐
│                         消息消费者                              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  LLM服务     │  │  工具服务    │  │  通知服务    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  分析服务    │  │  存储服务    │  │  邮件服务    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
```

**核心组件设计：**

1. **消息生产者**：
```python
class MessageProducer:
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
        self.connection = None
        self.channel = None
        self.confirmations = {}
    
    async def connect(self):
        """连接到消息队列"""
        if self.connection is None or self.connection.is_closed:
            self.connection = await aio_pika.connect_robust(self.connection_string)
            self.channel = await self.connection.channel()
            
            # 启用发布确认
            await self.channel.confirm_select()
            
            # 设置确认回调
            await self.channel.add_on_return_callback(self._on_return)
            await self.connection.add_on_close_callback(self._on_connection_closed)
    
    async def publish_message(self, 
                            exchange_name: str, 
                            routing_key: str, 
                            message: dict,
                            message_type: str = 'application/json',
                            headers: dict = None,
                            priority: int = 0,
                            delay: int = 0) -> bool:
        """发布消息"""
        try:
            await self.connect()
            
            # 创建消息属性
            properties = aio_pika.BasicProperties(
                content_type=message_type,
                headers=headers or {},
                priority=priority,
                delivery_mode=aio_pika.DeliveryMode.PERSISTENT
            )
            
            # 序列化消息
            if message_type == 'application/json':
                body = json.dumps(message).encode()
            else:
                body = str(message).encode()
            
            # 如果需要延迟发送
            if delay > 0:
                await self._publish_delayed_message(
                    exchange_name, routing_key, body, properties, delay
                )
            else:
                # 直接发布
                await self.channel.basic_publish(
                    exchange=exchange_name,
                    routing_key=routing_key,
                    body=body,
                    properties=properties
                )
            
            return True
            
        except Exception as e:
            print(f"Failed to publish message: {e}")
            return False
    
    async def _publish_delayed_message(self, 
                                    exchange_name: str, 
                                    routing_key: str, 
                                    body: bytes, 
                                    properties: aio_pika.BasicProperties,
                                    delay: int):
        """发布延迟消息"""
        # 创建延迟交换器
        delayed_exchange = f"{exchange_name}.delayed"
        delayed_routing_key = f"{routing_key}.delayed"
        
        # 设置延迟头
        delayed_headers = properties.headers or {}
        delayed_headers['x-delay'] = delay * 1000  # 毫秒
        
        delayed_properties = aio_pika.BasicProperties(
            content_type=properties.content_type,
            headers=delayed_headers,
            priority=properties.priority,
            delivery_mode=properties.delivery_mode
        )
        
        await self.channel.basic_publish(
            exchange=delayed_exchange,
            routing_key=delayed_routing_key,
            body=body,
            properties=delayed_properties
        )
    
    async def _on_return(self, channel, method, properties, body):
        """处理返回的消息"""
        print(f"Message returned: {method.routing_key}")
    
    async def _on_connection_closed(self, connection, reason):
        """处理连接关闭"""
        print(f"Connection closed: {reason}")
        self.connection = None
        self.channel = None

class BatchMessageProducer:
    def __init__(self, producer: MessageProducer, batch_size: int = 100, max_wait_time: float = 5.0):
        self.producer = producer
        self.batch_size = batch_size
        self.max_wait_time = max_wait_time
        self.pending_messages = []
        self.last_batch_time = time.time()
        self.batch_task = None
    
    async def add_message(self, exchange_name: str, routing_key: str, message: dict, **kwargs):
        """添加消息到批次"""
        self.pending_messages.append({
            'exchange': exchange_name,
            'routing_key': routing_key,
            'message': message,
            'kwargs': kwargs
        })
        
        # 检查是否需要发送批次
        if (len(self.pending_messages) >= self.batch_size or 
            time.time() - self.last_batch_time >= self.max_wait_time):
            await self._send_batch()
    
    async def _send_batch(self):
        """发送批次消息"""
        if not self.pending_messages:
            return
        
        try:
            # 批量发布消息
            tasks = []
            for msg_data in self.pending_messages:
                task = self.producer.publish_message(
                    msg_data['exchange'],
                    msg_data['routing_key'],
                    msg_data['message'],
                    **msg_data['kwargs']
                )
                tasks.append(task)
            
            # 并行发布
            await asyncio.gather(*tasks, return_exceptions=True)
            
        except Exception as e:
            print(f"Failed to send batch: {e}")
        
        finally:
            self.pending_messages.clear()
            self.last_batch_time = time.time()
```

2. **消息消费者**：
```python
class MessageConsumer:
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
        self.connection = None
        self.channel = None
        self.consumers = {}
        self.message_handlers = {}
        self.error_handlers = {}
    
    async def connect(self):
        """连接到消息队列"""
        if self.connection is None or self.connection.is_closed:
            self.connection = await aio_pika.connect_robust(self.connection_string)
            self.channel = await self.connection.channel()
            
            # 设置QoS
            await self.channel.set_qos(prefetch_count=10)
            
            # 设置连接关闭回调
            await self.connection.add_on_close_callback(self._on_connection_closed)
    
    async def start_consuming(self, 
                            queue_name: str, 
                            handler: Callable,
                            error_handler: Callable = None,
                            consumer_tag: str = None):
        """开始消费消息"""
        await self.connect()
        
        if consumer_tag is None:
            consumer_tag = f"consumer_{queue_name}_{int(time.time())}"
        
        # 注册处理器
        self.message_handlers[queue_name] = handler
        if error_handler:
            self.error_handlers[queue_name] = error_handler
        
        # 创建消费者
        queue = await self.channel.get_queue(queue_name)
        consumer = await queue.consume(
            self._on_message,
            consumer_tag=consumer_tag
        )
        
        self.consumers[consumer_tag] = {
            'queue': queue_name,
            'consumer': consumer,
            'handler': handler
        }
        
        print(f"Started consuming from queue {queue_name} with tag {consumer_tag}")
    
    async def _on_message(self, channel: aio_pika.Channel, method: aio_pika.spec.Basic.Deliver, 
                         properties: aio_pika.BasicProperties, body: bytes):
        """处理接收到的消息"""
        queue_name = method.routing_key
        message_id = properties.message_id or str(uuid.uuid4())
        
        try:
            # 解析消息
            message = self._parse_message(body, properties)
            
            # 处理消息
            result = await self._process_message(queue_name, message)
            
            # 确认消息
            await channel.basic_ack(method.delivery_tag)
            
        except Exception as e:
            print(f"Error processing message {message_id}: {e}")
            
            # 调用错误处理器
            if queue_name in self.error_handlers:
                try:
                    await self.error_handlers[queue_name](e, message, method, properties, body)
                except Exception as error_handler_error:
                    print(f"Error in error handler: {error_handler_error}")
            
            # 根据错误类型决定是否重新入队
            if self._should_retry(e):
                await channel.basic_nack(method.delivery_tag, requeue=True)
            else:
                await channel.basic_nack(method.delivery_tag, requeue=False)
    
    def _parse_message(self, body: bytes, properties: aio_pika.BasicProperties) -> dict:
        """解析消息"""
        content_type = properties.content_type or 'application/json'
        
        if content_type == 'application/json':
            return json.loads(body.decode())
        else:
            return {
                'body': body.decode(),
                'content_type': content_type,
                'headers': properties.headers or {}
            }
    
    async def _process_message(self, queue_name: str, message: dict) -> Any:
        """处理消息"""
        handler = self.message_handlers.get(queue_name)
        if not handler:
            raise ValueError(f"No handler registered for queue {queue_name}")
        
        return await handler(message)
    
    def _should_retry(self, error: Exception) -> bool:
        """判断是否应该重试"""
        # 网络错误可以重试
        if isinstance(error, (ConnectionError, TimeoutError)):
            return True
        
        # 业务错误不重试
        if isinstance(error, (ValueError, KeyError)):
            return False
        
        # 其他错误默认重试
        return True
    
    async def _on_connection_closed(self, connection, reason):
        """处理连接关闭"""
        print(f"Connection closed: {reason}")
        self.connection = None
        self.channel = None
        
        # 重新连接
        await self._reconnect()
    
    async def _reconnect(self):
        """重新连接"""
        while True:
            try:
                await self.connect()
                
                # 重新启动消费者
                for consumer_tag, consumer_info in self.consumers.items():
                    await self.start_consuming(
                        consumer_info['queue'],
                        consumer_info['handler'],
                        self.error_handlers.get(consumer_info['queue']),
                        consumer_tag
                    )
                
                break
                
            except Exception as e:
                print(f"Failed to reconnect: {e}")
                await asyncio.sleep(5)  # 5秒后重试

class RetryConsumer(MessageConsumer):
    def __init__(self, connection_string: str, max_retries: int = 3):
        super().__init__(connection_string)
        self.max_retries = max_retries
        self.retry_queue_name = "retry_queue"
    
    async def setup_retry_queues(self):
        """设置重试队列"""
        await self.connect()
        
        # 声明重试交换器
        await self.channel.exchange_declare(
            exchange='retry_exchange',
            exchange_type='direct',
            durable=True
        )
        
        # 声明重试队列
        await self.channel.queue_declare(
            queue=self.retry_queue_name,
            durable=True,
            arguments={
                'x-message-ttl': 60000,  # 1分钟TTL
                'x-dead-letter-exchange': 'main_exchange',
                'x-dead-letter-routing-key': 'original_queue'
            }
        )
        
        # 绑定重试队列
        await self.channel.queue_bind(
            queue=self.retry_queue_name,
            exchange='retry_exchange',
            routing_key=self.retry_queue_name
        )
    
    async def _process_message(self, queue_name: str, message: dict) -> Any:
        """处理消息（带重试）"""
        retry_count = message.get('headers', {}).get('x-retry-count', 0)
        
        try:
            return await super()._process_message(queue_name, message)
            
        except Exception as e:
            if retry_count < self.max_retries:
                # 发送到重试队列
                await self._send_to_retry_queue(queue_name, message, retry_count + 1)
                raise e
            else:
                # 超过重试次数，发送到死信队列
                await self._send_to_dead_letter_queue(queue_name, message)
                raise e
    
    async def _send_to_retry_queue(self, original_queue: str, message: dict, retry_count: int):
        """发送到重试队列"""
        headers = message.get('headers', {})
        headers['x-retry-count'] = retry_count
        headers['x-original-queue'] = original_queue
        
        await self.channel.basic_publish(
            exchange='retry_exchange',
            routing_key=self.retry_queue_name,
            body=json.dumps(message).encode(),
            properties=aio_pika.BasicProperties(
                headers=headers,
                delivery_mode=aio_pika.DeliveryMode.PERSISTENT
            )
        )
    
    async def _send_to_dead_letter_queue(self, original_queue: str, message: dict):
        """发送到死信队列"""
        dead_letter_queue = f"dead_letter_{original_queue}"
        
        # 确保死信队列存在
        await self.channel.queue_declare(
            queue=dead_letter_queue,
            durable=True
        )
        
        await self.channel.basic_publish(
            exchange='',
            routing_key=dead_letter_queue,
            body=json.dumps(message).encode(),
            properties=aio_pika.BasicProperties(
                delivery_mode=aio_pika.DeliveryMode.PERSISTENT
            )
        )
```

3. **消息路由和交换器**：
```python
class MessageRouter:
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
        self.connection = None
        self.channel = None
        self.exchanges = {}
        self.bindings = []
    
    async def connect(self):
        """连接到消息队列"""
        if self.connection is None or self.connection.is_closed:
            self.connection = await aio_pika.connect_robust(self.connection_string)
            self.channel = await self.connection.channel()
    
    async def setup_topology(self):
        """设置拓扑结构"""
        await self.connect()
        
        # 声明主交换器
        await self._declare_exchange('main_exchange', 'topic')
        
        # 声明延迟交换器
        await self._declare_exchange('delayed_exchange', 'x-delayed-message', {
            'x-delayed-type': 'topic'
        })
        
        # 声明服务交换器
        await self._declare_exchange('agent_exchange', 'direct')
        await self._declare_exchange('llm_exchange', 'direct')
        await self._declare_exchange('tool_exchange', 'direct')
        
        # 绑定交换器
        await self._bind_exchange('main_exchange', 'agent_exchange', 'agent.*')
        await self._bind_exchange('main_exchange', 'llm_exchange', 'llm.*')
        await self._bind_exchange('main_exchange', 'tool_exchange', 'tool.*')
    
    async def _declare_exchange(self, name: str, exchange_type: str, arguments: dict = None):
        """声明交换器"""
        await self.channel.exchange_declare(
            exchange=name,
            exchange_type=exchange_type,
            durable=True,
            arguments=arguments
        )
        
        self.exchanges[name] = {
            'type': exchange_type,
            'arguments': arguments
        }
    
    async def _bind_exchange(self, source: str, destination: str, routing_key: str):
        """绑定交换器"""
        await self.channel.exchange_bind(
            source=source,
            destination=destination,
            routing_key=routing_key
        )
        
        self.bindings.append({
            'source': source,
            'destination': destination,
            'routing_key': routing_key
        })
    
    async def create_queue(self, 
                          queue_name: str, 
                          exchange_name: str, 
                          routing_key: str,
                          arguments: dict = None):
        """创建队列并绑定到交换器"""
        await self.connect()
        
        # 声明队列
        await self.channel.queue_declare(
            queue=queue_name,
            durable=True,
            arguments=arguments
        )
        
        # 绑定队列到交换器
        await self.channel.queue_bind(
            queue=queue_name,
            exchange=exchange_name,
            routing_key=routing_key
        )
        
        print(f"Created queue {queue_name} bound to {exchange_name} with routing key {routing_key}")

class TopicRouter:
    def __init__(self, router: MessageRouter):
        self.router = router
    
    async def route_message(self, topic: str, message: dict):
        """根据主题路由消息"""
        # 解析主题
        topic_parts = topic.split('.')
        
        # 确定交换器和路由键
        if topic_parts[0] == 'agent':
            exchange = 'agent_exchange'
            routing_key = topic
        elif topic_parts[0] == 'llm':
            exchange = 'llm_exchange'
            routing_key = topic
        elif topic_parts[0] == 'tool':
            exchange = 'tool_exchange'
            routing_key = topic
        else:
            exchange = 'main_exchange'
            routing_key = topic
        
        # 发布消息
        producer = MessageProducer(self.router.connection_string)
        await producer.publish_message(exchange, routing_key, message)
```

---

## 4. 总结

### 4.1 系统设计要点

**核心设计原则：**

1. **可扩展性**：
   - 微服务架构支持独立扩展
   - 水平扩展和垂直扩展结合
   - 自动扩缩容机制

2. **高可用性**：
   - 多副本部署
   - 故障转移和恢复
   - 熔断和降级机制

3. **性能优化**：
   - 多级缓存策略
   - 连接池和资源复用
   - 异步处理和并发优化

4. **可维护性**：
   - 清晰的架构分层
   - 统一的接口设计
   - 完善的监控和日志

### 4.2 技术选型要点

**关键技术决策：**

1. **架构模式**：
   - 微服务架构：服务解耦和独立部署
   - 事件驱动：异步处理和松耦合
   - CQRS：读写分离和性能优化

2. **技术栈**：
   - 后端框架：FastAPI/Flask（Python）或Spring Boot（Java）
   - 数据库：PostgreSQL + MongoDB + Redis
   - 消息队列：RabbitMQ/Kafka
   - 缓存：Redis + Memcached

3. **部署和运维**：
   - 容器化：Docker + Kubernetes
   - 监控：Prometheus + Grafana
   - 日志：ELK Stack
   - 链路追踪：Jaeger/Zipkin

这些系统设计方案展示了如何构建一个现代化、高性能、可扩展的AI Agent平台，涵盖了从基础设施到应用层的完整技术栈。