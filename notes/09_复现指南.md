# Qwen-Agent 复现指南

## 1. 环境搭建

### 1.1 系统要求

**硬件要求：**
- CPU: 4核以上推荐
- 内存: 8GB以上推荐，16GB更佳
- 硬盘: 20GB以上可用空间
- GPU: 可选，推荐用于模型推理

**软件要求：**
- 操作系统: Linux/macOS/Windows
- Python: 3.8+ (推荐3.9或3.10)
- Git: 最新版本
- 虚拟环境: virtualenv或conda

### 1.2 环境配置

**步骤1：安装Python和虚拟环境**
```bash
# 检查Python版本
python --version
pip --version

# 创建虚拟环境
python -m venv qwen-agent-env

# 激活虚拟环境
# Linux/macOS:
source qwen-agent-env/bin/activate

# Windows:
qwen-agent-env\Scripts\activate

# 升级pip
pip install --upgrade pip
```

**步骤2：克隆项目源码**
```bash
# 克隆Qwen-Agent项目
git clone https://github.com/QwenLM/Qwen-Agent.git
cd Qwen-Agent

# 查看项目结构
ls -la
```

**步骤3：安装依赖**
```bash
# 安装基础依赖
pip install -r requirements.txt

# 安装开发依赖（可选）
pip install -r requirements-dev.txt

# 安装项目
pip install -e .
```

**步骤4：验证安装**
```bash
# 验证Qwen-Agent安装
python -c "import qwen_agent; print('Qwen-Agent installed successfully')"

# 检查版本
python -c "import qwen_agent; print(qwen_agent.__version__)"
```

### 1.3 配置API密钥

**获取API密钥：**
1. 阿里云DashScope: https://dashscope.aliyun.com/
2. OpenAI: https://platform.openai.com/
3. 其他模型提供商的API

**配置环境变量：**
```bash
# 创建配置文件
mkdir -p ~/.qwen_agent
touch ~/.qwen_agent/config.json

# 编辑配置文件
cat > ~/.qwen_agent/config.json << EOF
{
  "llm_configs": {
    "qwen_dashscope": {
      "model_type": "qwen_dashscope",
      "model": "qwen-turbo",
      "api_key": "your_dashscope_api_key",
      "api_base": "https://dashscope.aliyuncs.com/compatible-mode/v1"
    },
    "openai": {
      "model_type": "openai",
      "model": "gpt-3.5-turbo",
      "api_key": "your_openai_api_key"
    }
  },
  "default_llm": "qwen_dashscope"
}
EOF

# 或者使用环境变量
export DASHSCOPE_API_KEY="your_dashscope_api_key"
export OPENAI_API_KEY="your_openai_api_key"
```

## 2. 基础功能复现

### 2.1 第一个Agent程序

**创建简单的Assistant：**
```python
# first_agent.py
from qwen_agent.agents import Assistant
from qwen_agent.llm import get_chat_model

def main():
    # 创建LLM实例
    llm = get_chat_model({
        'model_type': 'qwen_dashscope',
        'model': 'qwen-turbo',
        'api_key': 'your_api_key'  # 替换为你的API密钥
    })
    
    # 创建Assistant
    agent = Assistant(
        llm=llm,
        system_message="You are a helpful assistant.",
        name="my_first_agent",
        description="My first AI agent"
    )
    
    # 对话循环
    print("=== My First Agent ===")
    print("Type 'quit' to exit")
    
    while True:
        user_input = input("\nYou: ")
        if user_input.lower() == 'quit':
            break
        
        # 构建消息
        messages = [{"role": "user", "content": user_input}]
        
        # 获取响应
        try:
            for response in agent.run(messages):
                print(f"Assistant: {response[0].content}")
        except Exception as e:
            print(f"Error: {e}")

if __name__ == "__main__":
    main()
```

**运行程序：**
```bash
python first_agent.py
```

**预期输出：**
```
=== My First Agent ===
Type 'quit' to exit

You: Hello, how are you?
Assistant: Hello! I'm doing well, thank you for asking. How can I help you today?

You: What can you do?
Assistant: I can help you with various tasks such as answering questions, providing information, assisting with problem-solving, and engaging in conversations on a wide range of topics. I'm here to be helpful and supportive in any way I can.

You: quit
```

### 2.2 带工具的Agent

**创建带工具的Assistant：**
```python
# tool_agent.py
from qwen_agent.agents import Assistant
from qwen_agent.llm import get_chat_model
from qwen_agent.tools import BaseTool, register_tool
import json
import time

# 自定义工具
@register_tool('calculator')
class CalculatorTool(BaseTool):
    description = 'Basic calculator for arithmetic operations'
    parameters = {
        'type': 'object',
        'properties': {
            'operation': {
                'type': 'string',
                'description': 'Operation to perform (add, subtract, multiply, divide)'
            },
            'a': {
                'type': 'number',
                'description': 'First number'
            },
            'b': {
                'type': 'number',
                'description': 'Second number'
            }
        },
        'required': ['operation', 'a', 'b']
    }
    
    def call(self, params: Union[str, dict], **kwargs) -> str:
        params = self._verify_json_format_args(params)
        
        operation = params['operation']
        a = params['a']
        b = params['b']
        
        if operation == 'add':
            result = a + b
        elif operation == 'subtract':
            result = a - b
        elif operation == 'multiply':
            result = a * b
        elif operation == 'divide':
            if b == 0:
                return "Error: Cannot divide by zero"
            result = a / b
        else:
            return f"Error: Unknown operation '{operation}'"
        
        return f"The result of {a} {operation} {b} is {result}"

@register_tool('time_getter')
class TimeGetterTool(BaseTool):
    description = 'Get current time and date'
    parameters = {
        'type': 'object',
        'properties': {
            'format': {
                'type': 'string',
                'description': 'Time format (default, iso, custom)'
            }
        },
        'required': []
    }
    
    def call(self, params: Union[str, dict], **kwargs) -> str:
        params = self._verify_json_format_args(params)
        time_format = params.get('format', 'default')
        
        import datetime
        now = datetime.datetime.now()
        
        if time_format == 'iso':
            return now.isoformat()
        elif time_format == 'custom':
            return now.strftime("%Y-%m-%d %H:%M:%S")
        else:
            return now.strftime("%A, %B %d, %Y at %I:%M:%S %p")

def main():
    # 创建LLM实例
    llm = get_chat_model({
        'model_type': 'qwen_dashscope',
        'model': 'qwen-turbo',
        'api_key': 'your_api_key'
    })
    
    # 创建带工具的Assistant
    agent = Assistant(
        llm=llm,
        system_message="You are a helpful assistant with access to calculation and time tools.",
        function_list=['calculator', 'time_getter'],
        name="tool_agent",
        description="Agent with calculator and time tools"
    )
    
    # 对话循环
    print("=== Tool Agent ===")
    print("Available tools: calculator, time_getter")
    print("Type 'quit' to exit")
    
    while True:
        user_input = input("\nYou: ")
        if user_input.lower() == 'quit':
            break
        
        # 构建消息
        messages = [{"role": "user", "content": user_input}]
        
        # 获取响应
        try:
            for response in agent.run(messages):
                print(f"Assistant: {response[0].content}")
        except Exception as e:
            print(f"Error: {e}")

if __name__ == "__main__":
    main()
```

**运行程序：**
```bash
python tool_agent.py
```

**预期输出：**
```
=== Tool Agent ===
Available tools: calculator, time_getter
Type 'quit' to exit

You: What's 25 * 4?
Assistant: I'll calculate 25 * 4 for you.
The result of 25 multiply 4 is 100

You: What time is it now?
Assistant: I'll get the current time for you.
Tuesday, December 10, 2024 at 03:30:45 PM

You: Calculate (15 + 8) * 3
Assistant: I'll help you calculate (15 + 8) * 3. Let me break this down:
First, I'll calculate 15 + 8 = 23
Then, I'll multiply that result by 3: 23 * 3 = 69

The final result of (15 + 8) * 3 is 69

You: quit
```

### 2.3 多模态Agent

**创建支持多模态的Agent：**
```python
# multimodal_agent.py
from qwen_agent.agents import Assistant
from qwen_agent.llm import get_chat_model
from qwen_agent.schema import Message, ContentItem
import base64

def encode_image(image_path):
    """编码图像为base64"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def main():
    # 创建LLM实例
    llm = get_chat_model({
        'model_type': 'qwen_dashscope',
        'model': 'qwen-vl-plus',  # 使用多模态模型
        'api_key': 'your_api_key'
    })
    
    # 创建多模态Assistant
    agent = Assistant(
        llm=llm,
        system_message="You are a helpful assistant that can understand and analyze images.",
        name="multimodal_agent",
        description="Agent with multimodal capabilities"
    )
    
    # 示例1：纯文本对话
    print("=== Example 1: Text Conversation ===")
    messages = [{"role": "user", "content": "Hello! Can you help me analyze images?"}]
    
    for response in agent.run(messages):
        print(f"Assistant: {response[0].content}")
    
    # 示例2：图像分析（如果有图像文件）
    print("\n=== Example 2: Image Analysis ===")
    
    # 创建多模态消息
    try:
        # 假设有一个测试图像
        image_path = "test_image.jpg"  # 替换为实际图像路径
        
        # 创建包含图像的消息
        multimodal_message = Message(
            role="user",
            content=[
                ContentItem(type="text", text="Please analyze this image and describe what you see."),
                ContentItem(type="image", image=f"file://{image_path}")
            ]
        )
        
        for response in agent.run([multimodal_message.to_dict()]):
            print(f"Assistant: {response[0].content}")
            
    except FileNotFoundError:
        print("Image file not found. Skipping image analysis example.")
    except Exception as e:
        print(f"Error in image analysis: {e}")
    
    # 示例3：文档分析
    print("\n=== Example 3: Document Analysis ===")
    
    try:
        # 假设有一个PDF文档
        doc_path = "sample.pdf"  # 替换为实际文档路径
        
        doc_message = Message(
            role="user",
            content=[
                ContentItem(type="text", text="Please analyze this document and summarize the key points."),
                ContentItem(type="file_url", file_url=f"file://{doc_path}")
            ]
        )
        
        for response in agent.run([doc_message.to_dict()]):
            print(f"Assistant: {response[0].content}")
            
    except FileNotFoundError:
        print("Document file not found. Skipping document analysis example.")
    except Exception as e:
        print(f"Error in document analysis: {e}")

if __name__ == "__main__":
    main()
```

## 3. 高级功能复现

### 3.1 RAG系统复现

**创建检索增强生成系统：**
```python
# rag_system.py
from qwen_agent.agents import Assistant
from qwen_agent.llm import get_chat_model
from qwen_agent.rags import VectorRAG
from qwen_agent.schema import Message
import os
import json

class CustomVectorRAG(VectorRAG):
    def __init__(self, llm_config, vector_store_path="./vector_store"):
        super().__init__(llm=llm_config, vector_store_path=vector_store_path)
        self.knowledge_base = []
    
    def add_text_knowledge(self, texts, metadata_list=None):
        """添加文本知识"""
        if metadata_list is None:
            metadata_list = [{} for _ in texts]
        
        documents = []
        for text, metadata in zip(texts, metadata_list):
            doc = {
                'text': text,
                'metadata': metadata
            }
            documents.append(doc)
        
        doc_ids = self.add_documents(documents)
        self.knowledge_base.extend(documents)
        
        return doc_ids
    
    def query_knowledge(self, query, top_k=3):
        """查询知识库"""
        retrieved_docs = self.retrieve(query, top_k=top_k)
        
        context = "Relevant information:\n"
        for i, doc in enumerate(retrieved_docs, 1):
            context += f"{i}. {doc['text']}\n"
            if doc.get('metadata'):
                context += f"   Source: {doc['metadata']}\n"
        
        return context

def main():
    # LLM配置
    llm_config = {
        'model_type': 'qwen_dashscope',
        'model': 'qwen-turbo',
        'api_key': 'your_api_key'
    }
    
    # 创建RAG系统
    rag = CustomVectorRAG(llm_config)
    
    # 添加知识库
    knowledge_texts = [
        "Qwen-Agent is a powerful framework for building AI agents with LLMs.",
        "It supports multiple LLM providers including Qwen, OpenAI, and Claude.",
        "The framework includes tools for code interpretation, web search, and document processing.",
        "Agents can be customized with system messages and function calling capabilities.",
        "Qwen-Agent supports both streaming and non-streaming response modes."
    ]
    
    metadata_list = [
        {"source": "README.md", "category": "introduction"},
        {"source": "docs/features.md", "category": "features"},
        {"source": "docs/tools.md", "category": "tools"},
        {"source": "docs/customization.md", "category": "customization"},
        {"source": "docs/usage.md", "category": "usage"}
    ]
    
    print("=== Building Knowledge Base ===")
    doc_ids = rag.add_text_knowledge(knowledge_texts, metadata_list)
    print(f"Added {len(doc_ids)} documents to knowledge base")
    
    # 创建RAG Agent
    rag_agent = Assistant(
        llm=get_chat_model(llm_config),
        system_message="You are a helpful assistant that answers questions based on the provided knowledge base.",
        name="rag_agent",
        description="RAG-enhanced assistant"
    )
    
    # 查询示例
    queries = [
        "What is Qwen-Agent?",
        "Which LLM providers are supported?",
        "What tools are available in Qwen-Agent?",
        "How can I customize agents in Qwen-Agent?",
        "Does Qwen-Agent support streaming responses?"
    ]
    
    print("\n=== RAG Query Examples ===")
    
    for query in queries:
        print(f"\nQuery: {query}")
        
        # 检索相关文档
        context = rag.query_knowledge(query, top_k=2)
        
        # 构建增强提示
        enhanced_prompt = f"""
        Based on the following knowledge base information, please answer the question:
        
        {context}
        
        Question: {query}
        
        Please provide a comprehensive answer based only on the provided information.
        """
        
        # 获取响应
        messages = [{"role": "user", "content": enhanced_prompt}]
        
        try:
            for response in rag_agent.run(messages):
                print(f"Answer: {response[0].content}")
        except Exception as e:
            print(f"Error: {e}")
        
        print("-" * 80)

if __name__ == "__main__":
    main()
```

### 3.2 多智能体协作复现

**创建多智能体协作系统：**
```python
# multi_agent_system.py
from qwen_agent.agents import Assistant, GroupChat
from qwen_agent.llm import get_chat_model
import time

def create_specialized_agents():
    """创建专业化智能体"""
    llm_config = {
        'model_type': 'qwen_dashscope',
        'model': 'qwen-turbo',
        'api_key': 'your_api_key'
    }
    
    # 技术专家
    tech_expert = Assistant(
        llm=get_chat_model(llm_config),
        system_message="""You are a technical expert specializing in software development, 
        system architecture, and emerging technologies. Provide detailed technical insights 
        and recommendations.""",
        name="tech_expert",
        description="Technical expert for software and systems"
    )
    
    # 商业分析师
    business_analyst = Assistant(
        llm=get_chat_model(llm_config),
        system_message="""You are a business analyst with expertise in market analysis, 
        business strategy, and product management. Focus on business value, market opportunities, 
        and strategic recommendations.""",
        name="business_analyst",
        description="Business analyst for strategy and planning"
    )
    
    # 用户体验专家
    ux_expert = Assistant(
        llm=get_chat_model(llm_config),
        system_message="""You are a UX/UI design expert with knowledge of user-centered design, 
        interface design principles, and user research. Provide insights on user experience, 
        interface design, and usability.""",
        name="ux_expert",
        description="UX/UI design expert"
    )
    
    # 项目经理
    project_manager = Assistant(
        llm=get_chat_model(llm_config),
        system_message="""You are a project manager with experience in agile methodologies, 
        team coordination, and project planning. Focus on timeline, resource allocation, 
        risk management, and execution strategy.""",
        name="project_manager",
        description="Project manager for planning and coordination"
    )
    
    return [tech_expert, business_analyst, ux_expert, project_manager]

def main():
    print("=== Multi-Agent Collaboration System ===")
    
    # 创建专业化智能体
    agents = create_specialized_agents()
    
    # 创建主持人
    moderator_config = {
        'model_type': 'qwen_dashscope',
        'model': 'qwen-turbo',
        'api_key': 'your_api_key'
    }
    
    moderator = Assistant(
        llm=get_chat_model(moderator_config),
        system_message="""You are a skilled facilitator who coordinates discussions between 
        multiple experts. Your role is to guide the conversation, ensure all perspectives 
        are considered, and help reach consensus. Ask clarifying questions and summarize 
        key points.""",
        name="moderator",
        description="Discussion moderator and facilitator"
    )
    
    # 创建多智能体系统
    group_chat = GroupChat(
        agents=agents,
        moderator=moderator,
        max_rounds=8,
        name="product_planning_team",
        description="Multi-agent team for comprehensive product planning"
    )
    
    # 复杂产品规划场景
    product_scenario = """
    We need to plan a new AI-powered mobile application for personal finance management. 
    The app should help users:
    1. Track expenses and income automatically
    2. Create and manage budgets
    3. Get personalized financial insights and recommendations
    4. Set and track financial goals
    5. Provide educational content about personal finance
    
    Please discuss the following aspects:
    - Technical architecture and technology stack
    - Market opportunity and business model
    - User experience and interface design
    - Development timeline and resource requirements
    - Potential challenges and mitigation strategies
    
    Each expert should provide detailed insights from their perspective, and we should 
    work towards a comprehensive product plan.
    """
    
    print(f"\n=== Starting Product Planning Discussion ===")
    print(f"Participants: {[agent.name for agent in agents]}")
    print(f"Moderator: {moderator.name}")
    print(f"Max rounds: {group_chat.max_rounds}")
    print("-" * 80)
    
    # 执行协作讨论
    start_time = time.time()
    
    messages = [{"role": "user", "content": product_scenario}]
    
    try:
        for response in group_chat.run(messages):
            print(f"Round {group_chat.current_round}:")
            print(f"Response: {response[0].content}")
            print("-" * 80)
            
            # 添加小延迟以便观察
            time.sleep(1)
    
    except Exception as e:
        print(f"Error during collaboration: {e}")
    
    execution_time = time.time() - start_time
    
    print(f"\n=== Collaboration Summary ===")
    print(f"Total execution time: {execution_time:.2f} seconds")
    print(f"Rounds completed: {group_chat.current_round}")
    print(f"Agents participated: {len(group_chat.agents)}")
    
    # 显示每个智能体的贡献
    if hasattr(group_chat, 'agent_responses'):
        print("\nIndividual contributions:")
        for agent_name, response in group_chat.agent_responses.items():
            contribution_length = len(response)
            print(f"  {agent_name}: {contribution_length} characters")
    
    print("\n=== Collaboration Complete ===")

if __name__ == "__main__":
    main()
```

### 3.3 自定义工具开发

**创建自定义工具：**
```python
# custom_tools.py
from qwen_agent.tools import BaseTool, register_tool
from qwen_agent.agents import Assistant
from qwen_agent.llm import get_chat_model
import json
import requests
import sqlite3
from datetime import datetime, timedelta
import os

# 天气查询工具
@register_tool('weather_forecast')
class WeatherForecastTool(BaseTool):
    description = 'Get weather forecast for a city'
    parameters = {
        'type': 'object',
        'properties': {
            'city': {
                'type': 'string',
                'description': 'City name to get weather for'
            },
            'days': {
                'type': 'integer',
                'description': 'Number of days for forecast (1-7)',
                'default': 1
            }
        },
        'required': ['city']
    }
    
    def call(self, params: Union[str, dict], **kwargs) -> str:
        params = self._verify_json_format_args(params)
        city = params['city']
        days = min(params.get('days', 1), 7)
        
        # 模拟天气API调用
        try:
            # 这里应该调用真实的天气API
            # 为了示例，我们返回模拟数据
            weather_data = self._get_mock_weather_data(city, days)
            
            result = f"Weather forecast for {city}:\n"
            for day in weather_data:
                result += f"Date: {day['date']}\n"
                result += f"Temperature: {day['temp_min']}°C - {day['temp_max']}°C\n"
                result += f"Condition: {day['condition']}\n"
                result += f"Humidity: {day['humidity']}%\n"
                result += f"Wind: {day['wind_speed']} km/h\n"
                result += "-" * 30 + "\n"
            
            return result.strip()
            
        except Exception as e:
            return f"Error getting weather data: {str(e)}"
    
    def _get_mock_weather_data(self, city, days):
        """生成模拟天气数据"""
        weather_conditions = ['Sunny', 'Cloudy', 'Rainy', 'Partly Cloudy']
        
        data = []
        base_date = datetime.now()
        
        for i in range(days):
            date = base_date + timedelta(days=i)
            condition = weather_conditions[i % len(weather_conditions)]
            
            data.append({
                'date': date.strftime('%Y-%m-%d'),
                'temp_min': 15 + i * 2,
                'temp_max': 25 + i * 2,
                'condition': condition,
                'humidity': 60 + i * 5,
                'wind_speed': 10 + i * 3
            })
        
        return data

# 数据库查询工具
@register_tool('database_query')
class DatabaseQueryTool(BaseTool):
    description = 'Query SQLite database with SQL'
    parameters = {
        'type': 'object',
        'properties': {
            'query': {
                'type': 'string',
                'description': 'SQL query to execute'
            },
            'database_path': {
                'type': 'string',
                'description': 'Path to SQLite database file',
                'default': 'sample.db'
            }
        },
        'required': ['query']
    }
    
    def call(self, params: Union[str, dict], **kwargs) -> str:
        params = self._verify_json_format_args(params)
        query = params['query']
        database_path = params.get('database_path', 'sample.db')
        
        # 安全检查：只允许SELECT查询
        query_upper = query.upper().strip()
        if not query_upper.startswith('SELECT'):
            return "Error: Only SELECT queries are allowed for security reasons."
        
        try:
            # 连接数据库
            conn = sqlite3.connect(database_path)
            cursor = conn.cursor()
            
            # 执行查询
            cursor.execute(query)
            
            # 获取结果
            columns = [description[0] for description in cursor.description]
            rows = cursor.fetchall()
            
            # 格式化结果
            if not rows:
                result = "Query executed successfully, no results returned."
            else:
                result = "Query Results:\n"
                result += "| " + " | ".join(columns) + " |\n"
                result += "|" + "|".join(["-" * (len(col) + 2) for col in columns]) + "|\n"
                
                for row in rows:
                    result += "| " + " | ".join(str(cell) for cell in row) + " |\n"
                
                result += f"\nTotal rows: {len(rows)}"
            
            conn.close()
            return result
            
        except sqlite3.Error as e:
            return f"Database error: {str(e)}"
        except Exception as e:
            return f"Error: {str(e)}"

# 文件处理工具
@register_tool('file_processor')
class FileProcessorTool(BaseTool):
    description = 'Process and analyze text files'
    parameters = {
        'type': 'object',
        'properties': {
            'file_path': {
                'type': 'string',
                'description': 'Path to the file to process'
            },
            'operation': {
                'type': 'string',
                'description': 'Operation to perform (count_words, count_lines, summarize, find_pattern)',
                'default': 'count_words'
            },
            'pattern': {
                'type': 'string',
                'description': 'Pattern to search for (required for find_pattern operation)'
            }
        },
        'required': ['file_path']
    }
    
    def call(self, params: Union[str, dict], **kwargs) -> str:
        params = self._verify_json_format_args(params)
        file_path = params['file_path']
        operation = params.get('operation', 'count_words')
        
        try:
            # 检查文件是否存在
            if not os.path.exists(file_path):
                return f"Error: File '{file_path}' not found."
            
            # 读取文件
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
            
            # 执行操作
            if operation == 'count_words':
                word_count = len(content.split())
                return f"Word count: {word_count}"
            
            elif operation == 'count_lines':
                line_count = len(content.split('\n'))
                return f"Line count: {line_count}"
            
            elif operation == 'summarize':
                lines = content.split('\n')
                summary_lines = lines[:5]  # 前5行作为摘要
                summary = '\n'.join(summary_lines)
                return f"File summary (first 5 lines):\n{summary}"
            
            elif operation == 'find_pattern':
                pattern = params.get('pattern')
                if not pattern:
                    return "Error: Pattern is required for find_pattern operation."
                
                import re
                matches = re.findall(pattern, content)
                return f"Found {len(matches)} matches for pattern '{pattern}'"
            
            else:
                return f"Error: Unknown operation '{operation}'"
                
        except Exception as e:
            return f"Error processing file: {str(e)}"

def create_sample_database():
    """创建示例数据库"""
    conn = sqlite3.connect('sample.db')
    cursor = conn.cursor()
    
    # 创建表
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS employees (
            id INTEGER PRIMARY KEY,
            name TEXT NOT NULL,
            department TEXT NOT NULL,
            salary REAL,
            hire_date TEXT
        )
    ''')
    
    # 插入示例数据
    employees = [
        (1, 'Alice Johnson', 'Engineering', 85000.0, '2022-01-15'),
        (2, 'Bob Smith', 'Marketing', 65000.0, '2022-03-20'),
        (3, 'Charlie Brown', 'Engineering', 95000.0, '2021-11-10'),
        (4, 'Diana Prince', 'HR', 70000.0, '2022-06-01'),
        (5, 'Eve Wilson', 'Marketing', 68000.0, '2022-08-15')
    ]
    
    cursor.executemany(
        'INSERT OR REPLACE INTO employees VALUES (?, ?, ?, ?, ?)',
        employees
    )
    
    conn.commit()
    conn.close()
    print("Sample database created successfully.")

def main():
    print("=== Custom Tools Demo ===")
    
    # 创建示例数据库
    create_sample_database()
    
    # 创建示例文件
    sample_text = """
    This is a sample text file for testing the file processor tool.
    It contains multiple lines of text with various words.
    The file processor can count words, lines, and search for patterns.
    You can use this tool to analyze text files efficiently.
    This demonstrates the flexibility of custom tools in Qwen-Agent.
    """
    
    with open('sample.txt', 'w', encoding='utf-8') as f:
        f.write(sample_text)
    
    print("Sample files created successfully.")
    
    # LLM配置
    llm_config = {
        'model_type': 'qwen_dashscope',
        'model': 'qwen-turbo',
        'api_key': 'your_api_key'
    }
    
    # 创建带自定义工具的Assistant
    agent = Assistant(
        llm=get_chat_model(llm_config),
        system_message="You are a helpful assistant with access to weather forecast, database query, and file processing tools.",
        function_list=['weather_forecast', 'database_query', 'file_processor'],
        name="custom_tools_agent",
        description="Agent with custom tools"
    )
    
    # 测试场景
    test_scenarios = [
        "What's the weather forecast for Beijing for the next 3 days?",
        "Can you query the employee database and show me all employees from the Engineering department?",
        "Please analyze the sample.txt file and tell me how many words it contains.",
        "Search for the word 'tool' in the sample.txt file.",
        "Get the current weather for Shanghai and also count the lines in sample.txt."
    ]
    
    print("\n=== Testing Custom Tools ===")
    
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\n--- Test Scenario {i} ---")
        print(f"User: {scenario}")
        
        messages = [{"role": "user", "content": scenario}]
        
        try:
            for response in agent.run(messages):
                print(f"Assistant: {response[0].content}")
        except Exception as e:
            print(f"Error: {e}")
        
        print("-" * 80)
    
    print("\n=== Custom Tools Demo Complete ===")

if __name__ == "__main__":
    main()
```

## 4. 部署和集成

### 4.1 Web服务部署

**创建Flask Web服务：**
```python
# web_service.py
from flask import Flask, request, jsonify, render_template
from qwen_agent.agents import Assistant
from qwen_agent.llm import get_chat_model
import threading
import json
from datetime import datetime

app = Flask(__name__)

# 全局Agent实例
agent = None

def initialize_agent():
    """初始化Agent"""
    global agent
    llm_config = {
        'model_type': 'qwen_dashscope',
        'model': 'qwen-turbo',
        'api_key': 'your_api_key'
    }
    
    agent = Assistant(
        llm=get_chat_model(llm_config),
        system_message="You are a helpful AI assistant.",
        name="web_agent",
        description="Web service agent"
    )

@app.route('/')
def index():
    """主页"""
    return render_template('index.html')

@app.route('/api/chat', methods=['POST'])
def chat():
    """聊天API"""
    try:
        data = request.json
        message = data.get('message', '')
        conversation_id = data.get('conversation_id', 'default')
        
        if not message:
            return jsonify({'error': 'Message is required'}), 400
        
        # 构建消息
        messages = [{"role": "user", "content": message}]
        
        # 获取响应
        response_text = ""
        for response in agent.run(messages):
            response_text += response[0].content
        
        return jsonify({
            'response': response_text,
            'conversation_id': conversation_id,
            'timestamp': datetime.now().isoformat()
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/health')
def health():
    """健康检查"""
    return jsonify({
        'status': 'healthy',
        'agent_ready': agent is not None,
        'timestamp': datetime.now().isoformat()
    })

if __name__ == '__main__':
    # 初始化Agent
    initialize_agent()
    
    # 启动Web服务
    print("Starting web service...")
    app.run(debug=True, host='0.0.0.0', port=5000)
```

**HTML模板 (templates/index.html):**
```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Qwen-Agent Web Interface</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .chat-container {
            height: 400px;
            overflow-y: auto;
            border: 1px solid #ddd;
            padding: 10px;
            margin-bottom: 20px;
            background-color: #fafafa;
        }
        .message {
            margin-bottom: 10px;
            padding: 10px;
            border-radius: 5px;
        }
        .user-message {
            background-color: #007bff;
            color: white;
            text-align: right;
        }
        .assistant-message {
            background-color: #e9ecef;
            color: #333;
        }
        .input-container {
            display: flex;
            gap: 10px;
        }
        #user-input {
            flex: 1;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        #send-button {
            padding: 10px 20px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        #send-button:hover {
            background-color: #0056b3;
        }
        .loading {
            text-align: center;
            color: #666;
            font-style: italic;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Qwen-Agent Web Interface</h1>
        <div class="chat-container" id="chat-container">
            <div class="message assistant-message">
                Hello! I'm your AI assistant. How can I help you today?
            </div>
        </div>
        <div class="input-container">
            <input type="text" id="user-input" placeholder="Type your message here..." onkeypress="handleKeyPress(event)">
            <button id="send-button" onclick="sendMessage()">Send</button>
        </div>
    </div>

    <script>
        let conversationId = 'conversation_' + Date.now();

        function handleKeyPress(event) {
            if (event.key === 'Enter') {
                sendMessage();
            }
        }

        async function sendMessage() {
            const input = document.getElementById('user-input');
            const message = input.value.trim();
            
            if (!message) return;

            // 添加用户消息到聊天界面
            addMessage(message, 'user');
            
            // 清空输入框
            input.value = '';
            
            // 显示加载状态
            addMessage('Thinking...', 'assistant', true);
            
            try {
                // 发送消息到服务器
                const response = await fetch('/api/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        message: message,
                        conversation_id: conversationId
                    })
                });
                
                const data = await response.json();
                
                // 移除加载消息
                removeLoadingMessage();
                
                if (data.error) {
                    addMessage('Error: ' + data.error, 'assistant');
                } else {
                    addMessage(data.response, 'assistant');
                }
                
            } catch (error) {
                removeLoadingMessage();
                addMessage('Error: Unable to connect to server', 'assistant');
            }
        }

        function addMessage(content, sender, isLoading = false) {
            const chatContainer = document.getElementById('chat-container');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender}-message`;
            if (isLoading) {
                messageDiv.className += ' loading';
            }
            messageDiv.textContent = content;
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        function removeLoadingMessage() {
            const loadingMessages = document.querySelectorAll('.loading');
            loadingMessages.forEach(msg => msg.remove());
        }

        // 页面加载时聚焦输入框
        document.addEventListener('DOMContentLoaded', function() {
            document.getElementById('user-input').focus();
        });
    </script>
</body>
</html>
```

**运行Web服务：**
```bash
# 安装Flask
pip install flask

# 运行Web服务
python web_service.py
```

**访问Web界面：**
- 打开浏览器访问 http://localhost:5000
- 使用Web界面与Agent对话

### 4.2 Docker部署

**创建Dockerfile：**
```dockerfile
# Dockerfile
FROM python:3.9-slim

# 设置工作目录
WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# 复制requirements文件
COPY requirements.txt .

# 安装Python依赖
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY . .

# 设置环境变量
ENV PYTHONPATH=/app
ENV DASHSCOPE_API_KEY=your_api_key_here

# 暴露端口
EXPOSE 5000

# 启动命令
CMD ["python", "web_service.py"]
```

**创建docker-compose.yml：**
```yaml
version: '3.8'

services:
  qwen-agent:
    build: .
    ports:
      - "5000:5000"
    environment:
      - DASHSCOPE_API_KEY=${DASHSCOPE_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    restart: unless-stopped
    
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

volumes:
  redis_data:
```

**构建和运行：**
```bash
# 构建镜像
docker-compose build

# 启动服务
docker-compose up -d

# 查看日志
docker-compose logs -f

# 停止服务
docker-compose down
```

## 5. 故障排除

### 5.1 常见问题

**问题1：ImportError: No module named 'qwen_agent'**
```bash
# 解决方案
pip install -e .
# 或者
export PYTHONPATH=/path/to/Qwen-Agent:$PYTHONPATH
```

**问题2：API密钥错误**
```bash
# 检查环境变量
echo $DASHSCOPE_API_KEY

# 或者检查配置文件
cat ~/.qwen_agent/config.json
```

**问题3：网络连接问题**
```bash
# 测试网络连接
curl -I https://dashscope.aliyuncs.com

# 设置代理（如果需要）
export HTTP_PROXY=http://proxy-server:port
export HTTPS_PROXY=http://proxy-server:port
```

**问题4：内存不足**
```bash
# 检查内存使用
free -h

# 优化内存使用
# 1. 减少并发请求数
# 2. 使用更小的模型
# 3. 增加系统内存
```

### 5.2 调试技巧

**启用详细日志：**
```python
import logging

# 设置日志级别
logging.basicConfig(level=logging.DEBUG)

# 或者使用环境变量
export QWEN_AGENT_LOG_LEVEL=DEBUG
```

**性能监控：**
```python
import time
import psutil

def monitor_performance():
    """监控系统性能"""
    cpu_percent = psutil.cpu_percent()
    memory_percent = psutil.virtual_memory().percent
    
    print(f"CPU: {cpu_percent}%, Memory: {memory_percent}%")
    
    # 记录到日志
    with open('performance.log', 'a') as f:
        f.write(f"{time.now()}: CPU {cpu_percent}%, Memory {memory_percent}%\n")
```

**错误处理：**
```python
import traceback

def safe_agent_call(agent, messages):
    """安全的Agent调用"""
    try:
        response = ""
        for chunk in agent.run(messages):
            response += chunk[0].content
        return response
    except Exception as e:
        print(f"Error in agent call: {e}")
        print(traceback.format_exc())
        return f"I apologize, but I encountered an error: {str(e)}"
```

## 6. 总结

通过本指南，你已经成功复现了Qwen-Agent的核心功能，包括：

1. **基础功能**：简单的Assistant、带工具的Agent、多模态Agent
2. **高级功能**：RAG系统、多智能体协作、自定义工具
3. **部署集成**：Web服务、Docker部署
4. **故障排除**：常见问题解决和调试技巧

### 下一步建议：

1. **深入学习**：阅读源码，理解内部实现机制
2. **扩展功能**：开发更多自定义工具和插件
3. **性能优化**：针对特定场景进行性能调优
4. **生产部署**：考虑安全性、监控、日志等生产环境需求

### 学习资源：

- [Qwen-Agent官方文档](https://github.com/QwenLM/Qwen-Agent)
- [API参考文档](https://qwen-agent.readthedocs.io/)
- [社区讨论](https://github.com/QwenLM/Qwen-Agent/discussions)
- [示例代码](https://github.com/QwenLM/Qwen-Agent/tree/main/examples)

希望这个复现指南能帮助你更好地理解和使用Qwen-Agent框架！